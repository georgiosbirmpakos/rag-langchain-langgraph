{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Greek Derby RAG System - Olympiakos vs Panathinaikos\n",
        "## RAG System for Greek Football Derby Analysis using Gazzetta.gr\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading Environment Variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key loaded: True\n",
            "Pinecone API Key loaded: True\n",
            "Pinecone Index Name: rag\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Verify API keys are loaded\n",
        "print(f\"OpenAI API Key loaded: {bool(os.getenv('OPENAI_API_KEY'))}\")\n",
        "print(f\"Pinecone API Key loaded: {bool(os.getenv('PINECONE_API_KEY'))}\")\n",
        "print(f\"Pinecone Index Name: {os.getenv('PINECONE_INDEX_NAME')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Selecting Chat Model for Greek Language\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Greek Language Test: Î“ÎµÎ¹Î± ÏƒÎ±Ï‚! ÎÎ±Î¹, Î¼Ï€Î¿ÏÏ Î½Î± Î¼Î¹Î»Î®ÏƒÏ‰ ÎµÎ»Î»Î·Î½Î¹ÎºÎ¬. Î ÏÏ‚ Î¼Ï€Î¿ÏÏ Î½Î± ÏƒÎ±Ï‚ Î²Î¿Î·Î¸Î®ÏƒÏ‰ ÏƒÎ®Î¼ÎµÏÎ±;\n"
          ]
        }
      ],
      "source": [
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "# Initialize GPT-4o-mini with Greek language support\n",
        "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
        "\n",
        "# Test Greek language capability\n",
        "test_response = llm.invoke(\"Î“ÎµÎ¹Î± ÏƒÎ±Ï‚! ÎœÏ€Î¿ÏÎµÎ¯Ï„Îµ Î½Î± Î¼Î¹Î»Î®ÏƒÎµÏ„Îµ ÎµÎ»Î»Î·Î½Î¹ÎºÎ¬;\")\n",
        "print(f\"Greek Language Test: {test_response.content}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Selecting Embeddings Model for Greek Text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Greek text embedding dimension: 1024\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# OpenAI Embedding Models optimized for multilingual content including Greek:\n",
        "# - text-embedding-3-small: 1536 dimensions (good for Greek)\n",
        "# - text-embedding-3-large: 3072 dimensions (best for Greek)\n",
        "# - text-embedding-3-small with dimensions=1024: 1024 dimensions (balanced)\n",
        "\n",
        "embeddings = OpenAIEmbeddings(\n",
        "    model=\"text-embedding-3-small\",\n",
        "    dimensions=1024  # Good balance for Greek text\n",
        ")\n",
        "\n",
        "# Test Greek text embedding\n",
        "test_text = \"ÎŸÎ»Ï…Î¼Ï€Î¹Î±ÎºÏŒÏ‚ vs Î Î±Î½Î±Î¸Î·Î½Î±ÏŠÎºÏŒÏ‚ - Ï„Î¿ Î¼ÎµÎ³Î¬Î»Î¿ Î½Ï„Î­ÏÎ¼Ï€Î¹ Ï„Î·Ï‚ Î•Î»Î»Î¬Î´Î±Ï‚\"\n",
        "test_embedding = embeddings.embed_query(test_text)\n",
        "print(f\"Greek text embedding dimension: {len(test_embedding)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setting up Vector Store for Greek Content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\PX\\anaconda3\\envs\\music-chatbot\\lib\\site-packages\\langchain_pinecone\\__init__.py:3: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
            "\n",
            "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
            "with: `from pydantic import BaseModel`\n",
            "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
            "\n",
            "  from langchain_pinecone.vectorstores import Pinecone, PineconeVectorStore\n",
            "Index host ignored when initializing with index object.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector store initialized for Greek content\n",
            "Index stats: {'dimension': 1024,\n",
            " 'index_fullness': 0.0,\n",
            " 'metric': 'cosine',\n",
            " 'namespaces': {'': {'vector_count': 160}},\n",
            " 'total_vector_count': 160,\n",
            " 'vector_type': 'dense'}\n"
          ]
        }
      ],
      "source": [
        "from langchain_pinecone import PineconeVectorStore\n",
        "from pinecone import Pinecone\n",
        "\n",
        "# Initialize Pinecone\n",
        "pc = Pinecone(api_key=os.getenv('PINECONE_API_KEY'))\n",
        "index = pc.Index(\"greekderby\")\n",
        "\n",
        "# Create vector store for Greek content\n",
        "vector_store = PineconeVectorStore(embedding=embeddings, index=index)\n",
        "\n",
        "print(f\"Vector store initialized for Greek content\")\n",
        "print(f\"Index stats: {index.describe_index_stats()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading Greek Football Content from Gazzetta.gr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading Greek football content from Gazzetta.gr...\n",
            "Loading: https://www.gazzetta.gr/football/superleague/olympiakos\n",
            "  No content found with selectors, trying without filtering...\n",
            "  Found 1 valid documents from https://www.gazzetta.gr/football/superleague/olympiakos\n",
            "Loading: https://www.gazzetta.gr/football/superleague/panathinaikos\n",
            "  No content found with selectors, trying without filtering...\n",
            "  Found 1 valid documents from https://www.gazzetta.gr/football/superleague/panathinaikos\n",
            "Loading: https://www.gazzetta.gr/football/superleague\n",
            "  No content found with selectors, trying without filtering...\n",
            "  Found 1 valid documents from https://www.gazzetta.gr/football/superleague\n",
            "Loaded 3 documents from Gazzetta.gr\n"
          ]
        }
      ],
      "source": [
        "import bs4\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from urllib.parse import urljoin, urlparse\n",
        "import time\n",
        "import requests\n",
        "\n",
        "# Set user agent to avoid blocking\n",
        "os.environ['USER_AGENT'] = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "\n",
        "# URLs to scrape from Gazzetta.gr related to Olympiakos and Panathinaikos\n",
        "greek_derby_urls = [\n",
        "    \"https://www.gazzetta.gr/football/superleague/olympiakos\",\n",
        "    \"https://www.gazzetta.gr/football/superleague/panathinaikos\",\n",
        "    \"https://www.gazzetta.gr/football/superleague\"\n",
        "]\n",
        "\n",
        "print(\"Loading Greek football content from Gazzetta.gr...\")\n",
        "\n",
        "# Load content from multiple URLs with better selectors\n",
        "all_docs = []\n",
        "for url in greek_derby_urls:\n",
        "    try:\n",
        "        print(f\"Loading: {url}\")\n",
        "        \n",
        "        # First try with broader selectors to get more content\n",
        "        loader = WebBaseLoader(\n",
        "            web_paths=(url,),\n",
        "            bs_kwargs=dict(\n",
        "                parse_only=bs4.SoupStrainer(\n",
        "                    class_=(\"article-content\", \"article-title\", \"article-body\", \"content\", \"post-content\", \n",
        "                           \"entry-content\", \"post-body\", \"article-text\", \"main-content\", \"story-content\",\n",
        "                           \"article\", \"post\", \"content-area\", \"main\", \"body\")\n",
        "                )\n",
        "            ),\n",
        "        )\n",
        "        docs = loader.load()\n",
        "        \n",
        "        # If no content found, try without any class filtering\n",
        "        if not docs or all(len(doc.page_content.strip()) < 100 for doc in docs):\n",
        "            print(f\"  No content found with selectors, trying without filtering...\")\n",
        "            loader_fallback = WebBaseLoader(web_paths=(url,))\n",
        "            docs = loader_fallback.load()\n",
        "        \n",
        "        # Filter out very short documents\n",
        "        valid_docs = [doc for doc in docs if len(doc.page_content.strip()) > 50]\n",
        "        all_docs.extend(valid_docs)\n",
        "        \n",
        "        print(f\"  Found {len(valid_docs)} valid documents from {url}\")\n",
        "        time.sleep(1)  # Be respectful to the server\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {url}: {e}\")\n",
        "        continue\n",
        "\n",
        "print(f\"Loaded {len(all_docs)} documents from Gazzetta.gr\")\n",
        "\n",
        "# If still no content, try a different approach with requests\n",
        "if len(all_docs) == 0 or all(len(doc.page_content.strip()) < 100 for doc in all_docs):\n",
        "    print(\"\\nTrying alternative approach with requests...\")\n",
        "    try:\n",
        "        response = requests.get(\"https://www.gazzetta.gr/football/superleague\", \n",
        "                              headers={'User-Agent': os.environ['USER_AGENT']})\n",
        "        if response.status_code == 200:\n",
        "            from langchain_core.documents import Document\n",
        "            # Create a document from the raw HTML content\n",
        "            fallback_doc = Document(\n",
        "                page_content=response.text,\n",
        "                metadata={\"source\": \"https://www.gazzetta.gr/football/superleague\", \"method\": \"requests\"}\n",
        "            )\n",
        "            all_docs.append(fallback_doc)\n",
        "            print(\"Added fallback document from requests\")\n",
        "    except Exception as e:\n",
        "        print(f\"Fallback approach also failed: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Splitting Greek Documents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Debugging loaded documents:\n",
            "\n",
            "Document 1:\n",
            "  Length: 19839 characters\n",
            "  Content preview: Î Î¿Î´ÏŒÏƒÏ†Î±Î¹ÏÎ¿ ÎŸÎ»Ï…Î¼Ï€Î¹Î±ÎºÏŒÏ‚ ÎÎ­Î± - Î•Î¹Î´Î®ÏƒÎµÎ¹Ï‚ - Î‘Î³ÏÎ½ÎµÏ‚ | gazzetta.gr\n",
            "   Î Î±ÏÎ¬ÎºÎ±Î¼ÏˆÎ· Ï€ÏÎ¿Ï‚ Ï„Î¿ ÎºÏ…ÏÎ¯Ï‰Ï‚ Ï€ÎµÏÎ¹ÎµÏ‡ÏŒÎ¼ÎµÎ½Î¿       Slogun:Î‘Ï†Î¿Ï Î· ÎšÎ·Ï†Î¹ÏƒÎ¹Î¬ Î´Î®Î»Ï‰ÏƒÎµ Î­Î´ÏÎ± Ï„Î¿ Î‘Î³ÏÎ¯Î½Î¹Î¿, Î¿ Î Î±Î½Î±Î¹Ï„Ï‰Î»Î¹ÎºÏŒÏ‚ Î¼Îµ Ï„Î­Ï„Î¿Î¹Î± Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± ÏˆÎ¬Ï‡Î½ÎµÎ¹ Î³Î®Ï€...\n",
            "  Metadata: {'source': 'https://www.gazzetta.gr/football/superleague/olympiakos', 'title': 'Î Î¿Î´ÏŒÏƒÏ†Î±Î¹ÏÎ¿ ÎŸÎ»Ï…Î¼Ï€Î¹Î±ÎºÏŒÏ‚ ÎÎ­Î± - Î•Î¹Î´Î®ÏƒÎµÎ¹Ï‚ - Î‘Î³ÏÎ½ÎµÏ‚ | gazzetta.gr', 'description': 'Î‘Î½Î±ÎºÎ±Î»ÏÏˆÏ„Îµ Ï„Î± Ï„ÎµÎ»ÎµÏ…Ï„Î±Î¯Î± Î½Î­Î± Î Î¿Î´ÏŒÏƒÏ†Î±Î¹ÏÎ¿ ÎŸÎ»Ï…Î¼Ï€Î¹Î±ÎºÏŒÏ‚ ÏƒÏ„Î¿ gazzetta.gr. Î•Î½Î·Î¼ÎµÏÏ‰Î¸ÎµÎ¯Ï„Îµ Ï€ÏÏÏ„Î¿Î¹ Î³Î¹Î± ÏŒÎ»ÎµÏ‚ Ï„Î¹Ï‚ ÎµÎ¾ÎµÎ»Î¯Î¾ÎµÎ¹Ï‚ Î Î¿Î´ÏŒÏƒÏ†Î±Î¹ÏÎ¿ ÎŸÎ»Ï…Î¼Ï€Î¹Î±ÎºÏŒÏ‚ ÎºÎ±Î¹ Î¼ÎµÎ¯Î½ÎµÏ„Îµ ÏƒÏ…Î½Ï„Î¿Î½Î¹ÏƒÎ¼Î­Î½Î¿Î¹!', 'language': 'el'}\n",
            "\n",
            "Document 2:\n",
            "  Length: 18613 characters\n",
            "  Content preview: Î Î¿Î´ÏŒÏƒÏ†Î±Î¹ÏÎ¿ Î Î±Î½Î±Î¸Î·Î½Î±ÏŠÎºÏŒÏ‚ ÎÎ­Î± - Î•Î¹Î´Î®ÏƒÎµÎ¹Ï‚ - Î‘Î³ÏÎ½ÎµÏ‚ | gazzetta.gr\n",
            "   Î Î±ÏÎ¬ÎºÎ±Î¼ÏˆÎ· Ï€ÏÎ¿Ï‚ Ï„Î¿ ÎºÏ…ÏÎ¯Ï‰Ï‚ Ï€ÎµÏÎ¹ÎµÏ‡ÏŒÎ¼ÎµÎ½Î¿       Slogun:Î‘Ï†Î¿Ï Î· ÎšÎ·Ï†Î¹ÏƒÎ¹Î¬ Î´Î®Î»Ï‰ÏƒÎµ Î­Î´ÏÎ± Ï„Î¿ Î‘Î³ÏÎ¯Î½Î¹Î¿, Î¿ Î Î±Î½Î±Î¹Ï„Ï‰Î»Î¹ÎºÏŒÏ‚ Î¼Îµ Ï„Î­Ï„Î¿Î¹Î± Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± ÏˆÎ¬Ï‡Î½ÎµÎ¹ Î³...\n",
            "  Metadata: {'source': 'https://www.gazzetta.gr/football/superleague/panathinaikos', 'title': 'Î Î¿Î´ÏŒÏƒÏ†Î±Î¹ÏÎ¿ Î Î±Î½Î±Î¸Î·Î½Î±ÏŠÎºÏŒÏ‚ ÎÎ­Î± - Î•Î¹Î´Î®ÏƒÎµÎ¹Ï‚ - Î‘Î³ÏÎ½ÎµÏ‚ | gazzetta.gr', 'description': 'Î‘Î½Î±ÎºÎ±Î»ÏÏˆÏ„Îµ Ï„Î± Ï„ÎµÎ»ÎµÏ…Ï„Î±Î¯Î± Î½Î­Î± Î Î¿Î´ÏŒÏƒÏ†Î±Î¹ÏÎ¿ Î Î±Î½Î±Î¸Î·Î½Î±ÏŠÎºÏŒÏ‚ ÏƒÏ„Î¿ gazzetta.gr. Î•Î½Î·Î¼ÎµÏÏ‰Î¸ÎµÎ¯Ï„Îµ Ï€ÏÏÏ„Î¿Î¹ Î³Î¹Î± ÏŒÎ»ÎµÏ‚ Ï„Î¹Ï‚ ÎµÎ¾ÎµÎ»Î¯Î¾ÎµÎ¹Ï‚ Î Î¿Î´ÏŒÏƒÏ†Î±Î¹ÏÎ¿ Î Î±Î½Î±Î¸Î·Î½Î±ÏŠÎºÏŒÏ‚ ÎºÎ±Î¹ Î¼ÎµÎ¯Î½ÎµÏ„Îµ ÏƒÏ…Î½Ï„Î¿Î½Î¹ÏƒÎ¼Î­Î½Î¿Î¹!', 'language': 'el'}\n",
            "\n",
            "Document 3:\n",
            "  Length: 16414 characters\n",
            "  Content preview: Superleague ÎÎ­Î± & Î•Î¹Î´Î®ÏƒÎµÎ¹Ï‚ | gazzetta.gr\n",
            "   Î Î±ÏÎ¬ÎºÎ±Î¼ÏˆÎ· Ï€ÏÎ¿Ï‚ Ï„Î¿ ÎºÏ…ÏÎ¯Ï‰Ï‚ Ï€ÎµÏÎ¹ÎµÏ‡ÏŒÎ¼ÎµÎ½Î¿       Slogun:Î‘Ï†Î¿Ï Î· ÎšÎ·Ï†Î¹ÏƒÎ¹Î¬ Î´Î®Î»Ï‰ÏƒÎµ Î­Î´ÏÎ± Ï„Î¿ Î‘Î³ÏÎ¯Î½Î¹Î¿, Î¿ Î Î±Î½Î±Î¹Ï„Ï‰Î»Î¹ÎºÏŒÏ‚ Î¼Îµ Ï„Î­Ï„Î¿Î¹Î± Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± ÏˆÎ¬Ï‡Î½ÎµÎ¹ Î³Î®Ï€ÎµÎ´Î¿ ÏƒÏ„Î· Î˜ÎµÏƒÏƒÎ±Î»Î¿Î½Î¯ÎºÎ·...\n",
            "  Metadata: {'source': 'https://www.gazzetta.gr/football/superleague', 'title': 'Superleague ÎÎ­Î± & Î•Î¹Î´Î®ÏƒÎµÎ¹Ï‚ | gazzetta.gr', 'description': 'Superleague: Î¤ÎµÎ»ÎµÏ…Ï„Î±Î¯Î± Î½Î­Î±, Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±, Ï€ÏÏŒÎ³ÏÎ±Î¼Î¼Î± ÎºÎ±Î¹ Î²Î±Î¸Î¼Î¿Î»Î¿Î³Î¯ÎµÏ‚! ÎŒÎ»ÎµÏ‚ Î¿Î¹ Ï„ÎµÎ»ÎµÏ…Ï„Î±Î¯ÎµÏ‚ ÎµÎ¹Î´Î®ÏƒÎµÎ¹Ï‚ Î³Î¹Î± Ï„Î¿ Super League ÏƒÏ„Î¿ Gazzetta.gr', 'language': 'el'}\n",
            "\n",
            "Created 161 text chunks from Greek content\n",
            "\n",
            "Sample chunk content:\n",
            "Length: 59 characters\n",
            "Content: Î Î¿Î´ÏŒÏƒÏ†Î±Î¹ÏÎ¿ ÎŸÎ»Ï…Î¼Ï€Î¹Î±ÎºÏŒÏ‚ ÎÎ­Î± - Î•Î¹Î´Î®ÏƒÎµÎ¹Ï‚ - Î‘Î³ÏÎ½ÎµÏ‚ | gazzetta.gr...\n"
          ]
        }
      ],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Debug: Check what's actually in the loaded documents\n",
        "print(\"Debugging loaded documents:\")\n",
        "for i, doc in enumerate(all_docs):\n",
        "    print(f\"\\nDocument {i+1}:\")\n",
        "    print(f\"  Length: {len(doc.page_content)} characters\")\n",
        "    print(f\"  Content preview: {doc.page_content[:200]}...\")\n",
        "    print(f\"  Metadata: {doc.metadata}\")\n",
        "\n",
        "# Try with smaller chunk size to see if we can get any chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,  # Reduced from 1000\n",
        "    chunk_overlap=100,  # Reduced from 200\n",
        "    separators=[\"\\n\\n\", \"\\n\", \". \", \"! \", \"? \", \" \", \"\"]  # Greek-friendly separators\n",
        ")\n",
        "\n",
        "all_splits = text_splitter.split_documents(all_docs)\n",
        "print(f\"\\nCreated {len(all_splits)} text chunks from Greek content\")\n",
        "\n",
        "# If still 0 chunks, try even smaller\n",
        "if len(all_splits) == 0:\n",
        "    print(\"\\nTrying with even smaller chunks...\")\n",
        "    text_splitter_small = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=100,  # Very small chunks\n",
        "        chunk_overlap=20,\n",
        "        separators=[\"\\n\", \". \", \"! \", \"? \", \" \", \"\"]\n",
        "    )\n",
        "    all_splits = text_splitter_small.split_documents(all_docs)\n",
        "    print(f\"Created {len(all_splits)} text chunks with small size\")\n",
        "\n",
        "# Show sample chunks if any were created\n",
        "if all_splits:\n",
        "    print(f\"\\nSample chunk content:\")\n",
        "    print(f\"Length: {len(all_splits[0].page_content)} characters\")\n",
        "    print(f\"Content: {all_splits[0].page_content[:300]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Storing Greek Content in Vector Database\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Storing Greek football content in vector database...\n",
            "Vector database stats: {'dimension': 1024,\n",
            " 'index_fullness': 0.0,\n",
            " 'metric': 'cosine',\n",
            " 'namespaces': {'': {'vector_count': 193}},\n",
            " 'total_vector_count': 193,\n",
            " 'vector_type': 'dense'}\n",
            "Total vectors: 193\n"
          ]
        }
      ],
      "source": [
        "# Clear existing content and add new Greek content\n",
        "print(\"Storing Greek football content in vector database...\")\n",
        "\n",
        "# Add documents to vector store\n",
        "_ = vector_store.add_documents(documents=all_splits)\n",
        "\n",
        "# Check index stats\n",
        "stats = index.describe_index_stats()\n",
        "print(f\"Vector database stats: {stats}\")\n",
        "print(f\"Total vectors: {stats['total_vector_count']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating Greek Language RAG Prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Greek RAG prompt created successfully\n",
            "Prompt template: \n",
            "Î•Î¯ÏƒÏ„Îµ Î­Î½Î±Ï‚ Î²Î¿Î·Î¸ÏŒÏ‚ Î³Î¹Î± ÎµÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚ ÏƒÏ‡ÎµÏ„Î¹ÎºÎ¬ Î¼Îµ Ï„Î¿ ÎµÎ»Î»Î·Î½Î¹ÎºÏŒ Ï€Î¿Î´ÏŒÏƒÏ†Î±Î¹ÏÎ¿ ÎºÎ±Î¹ Ï„Î¿ Î½Ï„Î­ÏÎ¼Ï€Î¹ ÎŸÎ»Ï…Î¼Ï€Î¹Î±ÎºÏŒÏ‚-Î Î±Î½Î±Î¸Î·Î½...\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Custom Greek language prompt for football derby questions\n",
        "greek_prompt_template = \"\"\"\n",
        "Î•Î¯ÏƒÏ„Îµ Î­Î½Î±Ï‚ Î²Î¿Î·Î¸ÏŒÏ‚ Î³Î¹Î± ÎµÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚ ÏƒÏ‡ÎµÏ„Î¹ÎºÎ¬ Î¼Îµ Ï„Î¿ ÎµÎ»Î»Î·Î½Î¹ÎºÏŒ Ï€Î¿Î´ÏŒÏƒÏ†Î±Î¹ÏÎ¿ ÎºÎ±Î¹ Ï„Î¿ Î½Ï„Î­ÏÎ¼Ï€Î¹ ÎŸÎ»Ï…Î¼Ï€Î¹Î±ÎºÏŒÏ‚-Î Î±Î½Î±Î¸Î·Î½Î±ÏŠÎºÏŒÏ‚.\n",
        "Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®ÏƒÏ„Îµ Ï„Î± Ï€Î±ÏÎ±ÎºÎ¬Ï„Ï‰ ÎºÎ¿Î¼Î¼Î¬Ï„Î¹Î± Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¹ÏÎ½ Î³Î¹Î± Î½Î± Î±Ï€Î±Î½Ï„Î®ÏƒÎµÏ„Îµ ÏƒÏ„Î·Î½ ÎµÏÏÏ„Î·ÏƒÎ·.\n",
        "Î‘Î½ Î´ÎµÎ½ Î³Î½Ï‰ÏÎ¯Î¶ÎµÏ„Îµ Ï„Î·Î½ Î±Ï€Î¬Î½Ï„Î·ÏƒÎ·, Î±Ï€Î»Î¬ Ï€ÎµÎ¯Ï„Îµ ÏŒÏ„Î¹ Î´ÎµÎ½ Î³Î½Ï‰ÏÎ¯Î¶ÎµÏ„Îµ.\n",
        "Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®ÏƒÏ„Îµ Î¼Î­Ï‡ÏÎ¹ Ï„ÏÎµÎ¹Ï‚ Ï€ÏÎ¿Ï„Î¬ÏƒÎµÎ¹Ï‚ ÎºÎ±Î¹ ÎºÏÎ±Ï„Î®ÏƒÏ„Îµ Ï„Î·Î½ Î±Ï€Î¬Î½Ï„Î·ÏƒÎ· ÏƒÏ…Î½Î¿Ï€Ï„Î¹ÎºÎ®.\n",
        "Î‘Ï€Î±Î½Ï„Î®ÏƒÏ„Îµ ÏƒÏ„Î± ÎµÎ»Î»Î·Î½Î¹ÎºÎ¬.\n",
        "\n",
        "Î•ÏÏÏ„Î·ÏƒÎ·: {question}\n",
        "Î ÎµÏÎ¹ÎµÏ‡ÏŒÎ¼ÎµÎ½Î¿: {context}\n",
        "Î‘Ï€Î¬Î½Ï„Î·ÏƒÎ·:\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"question\", \"context\"],\n",
        "    template=greek_prompt_template\n",
        ")\n",
        "\n",
        "print(\"Greek RAG prompt created successfully\")\n",
        "print(f\"Prompt template: {prompt.template[:100]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setting up Greek RAG Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Greek RAG functions defined successfully\n"
          ]
        }
      ],
      "source": [
        "from typing_extensions import List, TypedDict\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "# Define state for Greek RAG application\n",
        "class GreekDerbyState(TypedDict):\n",
        "    question: str\n",
        "    context: List[Document]\n",
        "    answer: str\n",
        "\n",
        "# Define application steps for Greek content\n",
        "def retrieve_greek_content(state: GreekDerbyState):\n",
        "    \"\"\"Retrieve relevant Greek football content based on question\"\"\"\n",
        "    retrieved_docs = vector_store.similarity_search(\n",
        "        state[\"question\"], \n",
        "        k=4  # Get top 4 most relevant documents\n",
        "    )\n",
        "    return {\"context\": retrieved_docs}\n",
        "\n",
        "def generate_greek_answer(state: GreekDerbyState):\n",
        "    \"\"\"Generate answer in Greek based on retrieved context\"\"\"\n",
        "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
        "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
        "    response = llm.invoke(messages)\n",
        "    return {\"answer\": response.content}\n",
        "\n",
        "print(\"Greek RAG functions defined successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Building the Greek RAG LangGraph\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Greek Derby RAG graph compiled successfully\n",
            "Graph nodes: ['__start__', 'retrieve_greek_content', 'generate_greek_answer', '__end__']\n"
          ]
        }
      ],
      "source": [
        "from langgraph.graph import START, StateGraph\n",
        "\n",
        "# Build the Greek RAG graph\n",
        "graph_builder = StateGraph(GreekDerbyState)\n",
        "graph_builder.add_sequence([retrieve_greek_content, generate_greek_answer])\n",
        "graph_builder.add_edge(START, \"retrieve_greek_content\")\n",
        "\n",
        "# Compile the graph\n",
        "greek_derby_graph = graph_builder.compile()\n",
        "\n",
        "print(\"Greek Derby RAG graph compiled successfully\")\n",
        "print(f\"Graph nodes: {list(greek_derby_graph.get_graph().nodes.keys())}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing the Greek Derby RAG System\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing Greek Derby RAG System...\n",
            "==================================================\n",
            "\n",
            "Î•ÏÏÏ„Î·ÏƒÎ· 1: Î Î¿Î¹Î± ÎµÎ¯Î½Î±Î¹ Î· Î¹ÏƒÏ„Î¿ÏÎ¯Î± Ï„Î¿Ï… Î½Ï„Î­ÏÎ¼Ï€Î¹ ÎŸÎ»Ï…Î¼Ï€Î¹Î±ÎºÏŒÏ‚-Î Î±Î½Î±Î¸Î·Î½Î±ÏŠÎºÏŒÏ‚;\n",
            "------------------------------\n",
            "Î‘Ï€Î¬Î½Ï„Î·ÏƒÎ·: Î— Î¹ÏƒÏ„Î¿ÏÎ¯Î± Ï„Î¿Ï… Î½Ï„Î­ÏÎ¼Ï€Î¹ ÎŸÎ»Ï…Î¼Ï€Î¹Î±ÎºÏŒÏ‚-Î Î±Î½Î±Î¸Î·Î½Î±ÏŠÎºÏŒÏ‚ ÎµÎ¯Î½Î±Î¹ Î³ÎµÎ¼Î¬Ï„Î· ÎµÎ½Ï„Î¬ÏƒÎµÎ¹Ï‚ ÎºÎ±Î¹ Î±Î½Ï„Î±Î³Ï‰Î½Î¹ÏƒÎ¼ÏŒ, ÎºÎ±Î¸ÏÏ‚ Ï€ÏÏŒÎºÎµÎ¹Ï„Î±Î¹ Î³Î¹Î± Î¼Î¯Î± Î±Ï€ÏŒ Ï„Î¹Ï‚ Ï€Î¹Î¿ Î¹ÏƒÏ„Î¿ÏÎ¹ÎºÎ­Ï‚ Î±Î½Ï„Î¹Ï€Î±ÏÎ±Î¸Î­ÏƒÎµÎ¹Ï‚ ÏƒÏ„Î¿ ÎµÎ»Î»Î·Î½Î¹ÎºÏŒ Ï€Î¿Î´ÏŒÏƒÏ†Î±Î¹ÏÎ¿. ÎŸÎ¹ Î´ÏÎ¿ Î¿Î¼Î¬Î´ÎµÏ‚, Î³Î½Ï‰ÏƒÏ„Î­Ï‚ ÎºÎ±Î¹ Ï‰Ï‚ \"Î±Î¹ÏÎ½Î¹Î¿Î¹ Î±Î½Ï„Î¯Ï€Î±Î»Î¿Î¹\", Î­Ï‡Î¿Ï…Î½ ÏƒÏ…Î½Î±Î½Ï„Î·Î¸ÎµÎ¯ Ï€Î¿Î»Î»Î­Ï‚ Ï†Î¿ÏÎ­Ï‚ ÎºÎ±Î¹ Î¿Î¹ Î±Î³ÏÎ½ÎµÏ‚ Ï„Î¿Ï…Ï‚ ÏƒÏ…Ï‡Î½Î¬ ÎºÏÎ¯Î½Î¿Ï…Î½ Ï„Î¯Ï„Î»Î¿Ï…Ï‚ ÎºÎ±Î¹ Ï†Î¹Î»Î¿Î´Î¿Î¾Î¯ÎµÏ‚. Î¤Î¿ Î½Ï„Î­ÏÎ¼Ï€Î¹ ÏƒÏ…Î½Î®Î¸Ï‰Ï‚ ÏƒÏ…Î½Î¿Î´ÎµÏÎµÏ„Î±Î¹ Î±Ï€ÏŒ Ï€Î¬Î¸Î¿Ï‚ ÎºÎ±Î¹ ÎµÎ¯Î½Î±Î¹ Î³ÎµÎ¼Î¬Ï„Î¿ ÎµÎ¹Î´Î¹ÎºÎ­Ï‚ ÏƒÏ…Î½Î¸Î®ÎºÎµÏ‚, ÏŒÏ€Ï‰Ï‚ Î±Î»Î»Î±Î³Î­Ï‚ Ï€ÏÎ¿Ï€Î¿Î½Î·Ï„ÏÎ½ ÎºÎ±Î¹ Î¬Î»Î»ÎµÏ‚ ÏƒÏ…Î³ÎºÏ…ÏÎ¯ÎµÏ‚ Ï€Î¿Ï… ÎµÏ€Î·ÏÎµÎ¬Î¶Î¿Ï…Î½ Ï„Î·Î½ ÏˆÏ…Ï‡Î¿Î»Î¿Î³Î¯Î± Ï„Ï‰Î½ Î¿Î¼Î¬Î´Ï‰Î½.\n",
            "\n",
            "\n",
            "Î•ÏÏÏ„Î·ÏƒÎ· 2: Î Î¿Î¹Î¿Ï‚ Î­Ï‡ÎµÎ¹ ÎºÎµÏÎ´Î¯ÏƒÎµÎ¹ Ï€ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎµÏ‚ Ï†Î¿ÏÎ­Ï‚ Ï„Î¿ Î½Ï„Î­ÏÎ¼Ï€Î¹;\n",
            "------------------------------\n",
            "Î‘Ï€Î¬Î½Ï„Î·ÏƒÎ·: Î”ÎµÎ½ Î³Î½Ï‰ÏÎ¯Î¶Ï‰.\n",
            "\n",
            "\n",
            "Î•ÏÏÏ„Î·ÏƒÎ· 3: Î Î¿Î¹Î± ÎµÎ¯Î½Î±Î¹ Ï„Î± Ï€Î¹Î¿ Î±Î¾Î­Ï‡Î±ÏƒÏ„Î± Î³ÎºÎ¿Î» ÏƒÏ„Î¿ Î½Ï„Î­ÏÎ¼Ï€Î¹;\n",
            "------------------------------\n",
            "Î‘Ï€Î¬Î½Ï„Î·ÏƒÎ·: Î”ÎµÎ½ Î³Î½Ï‰ÏÎ¯Î¶Ï‰ ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î± Ï€Î¿Î¹Î± ÎµÎ¯Î½Î±Î¹ Ï„Î± Ï€Î¹Î¿ Î±Î¾Î­Ï‡Î±ÏƒÏ„Î± Î³ÎºÎ¿Î» ÏƒÏ„Î¿ Î½Ï„Î­ÏÎ¼Ï€Î¹ ÎŸÎ»Ï…Î¼Ï€Î¹Î±ÎºÎ¿Ï-Î Î±Î½Î±Î¸Î·Î½Î±ÏŠÎºÎ¿Ï.\n",
            "\n",
            "\n",
            "Î•ÏÏÏ„Î·ÏƒÎ· 4: Î Î¿Î¹Î¿Î¹ ÎµÎ¯Î½Î±Î¹ Î¿Î¹ ÎºÎ¿ÏÏ…Ï†Î±Î¯Î¿Î¹ Ï€Î±Î¯ÎºÏ„ÎµÏ‚ Ï€Î¿Ï… Î­Ï‡Î¿Ï…Î½ Î±Î³Ï‰Î½Î¹ÏƒÏ„ÎµÎ¯ ÏƒÏ„Î¿ Î½Ï„Î­ÏÎ¼Ï€Î¹;\n",
            "------------------------------\n",
            "Î‘Ï€Î¬Î½Ï„Î·ÏƒÎ·: Î”ÎµÎ½ Î³Î½Ï‰ÏÎ¯Î¶Ï‰ Ï€Î¿Î¹Î¿Ï…Ï‚ ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î± ÎºÎ¿ÏÏ…Ï†Î±Î¯Î¿Ï…Ï‚ Ï€Î±Î¯ÎºÏ„ÎµÏ‚ Î­Ï‡Î¿Ï…Î½ Î±Î³Ï‰Î½Î¹ÏƒÏ„ÎµÎ¯ ÏƒÏ„Î¿ Î½Ï„Î­ÏÎ¼Ï€Î¹ ÎŸÎ»Ï…Î¼Ï€Î¹Î±ÎºÏŒÏ‚-Î Î±Î½Î±Î¸Î·Î½Î±ÏŠÎºÏŒÏ‚.\n",
            "\n",
            "\n",
            "Î•ÏÏÏ„Î·ÏƒÎ· 5: Î Î¿Î¹Î± ÎµÎ¯Î½Î±Î¹ Î· ÏƒÎ·Î¼Î±ÏƒÎ¯Î± Ï„Î¿Ï… Î½Ï„Î­ÏÎ¼Ï€Î¹ Î³Î¹Î± Ï„Î¿Ï…Ï‚ Ï†Î¹Î»Î¬Î¸Î»Î¿Ï…Ï‚;\n",
            "------------------------------\n",
            "Î‘Ï€Î¬Î½Ï„Î·ÏƒÎ·: Î¤Î¿ Î½Ï„Î­ÏÎ¼Ï€Î¹ ÎŸÎ»Ï…Î¼Ï€Î¹Î±ÎºÎ¿Ï - Î Î±Î½Î±Î¸Î·Î½Î±ÏŠÎºÎ¿Ï ÎµÎ¯Î½Î±Î¹ Î¹Î´Î¹Î±Î¯Ï„ÎµÏÎ± ÏƒÎ·Î¼Î±Î½Ï„Î¹ÎºÏŒ Î³Î¹Î± Ï„Î¿Ï…Ï‚ Ï†Î¹Î»Î¬Î¸Î»Î¿Ï…Ï‚ ÎºÎ±Î¸ÏÏ‚ ÏƒÏ…Î¼Î²Î¿Î»Î¯Î¶ÎµÎ¹ Î¼Î¹Î± Î²Î±Î¸Î¹Î¬ ÏÎ¹Î¶Ï‰Î¼Î­Î½Î· rivality ÎºÎ±Î¹ Î­Î½Ï„Î¿Î½Î± ÏƒÏ…Î½Î±Î¹ÏƒÎ¸Î®Î¼Î±Ï„Î±. Î“Î¹Î± Ï„Î¿Ï…Ï‚ Â«Î¼Ï€Î±ÏÎ¿Ï…Ï„Î¿ÎºÎ±Ï€Î½Î¹ÏƒÎ¼Î­Î½Î¿Ï…Ï‚Â» Ï†Î¹Î»Î¬Î¸Î»Î¿Ï…Ï‚, Î· ÏƒÎ·Î¼Î±ÏƒÎ¯Î± Ï„Î¿Ï… Î±Î³ÏÎ½Î± Ï€ÏÎ¿Î­ÏÏ‡ÎµÏ„Î±Î¹ Î±Ï€ÏŒ Ï„Î·Î½ Î¹ÏƒÏ„Î¿ÏÎ¯Î± ÎºÎ±Î¹ Ï„Î·Î½ Ï€Î±ÏÎ¬Î´Î¿ÏƒÎ· Î¼ÎµÏ„Î±Î¾Ï Ï„Ï‰Î½ Î´ÏÎ¿ Î¿Î¼Î¬Î´Ï‰Î½. ÎšÎ¬Î¸Îµ Î½Ï„Î­ÏÎ¼Ï€Î¹ Ï€Î±Î¯ÏÎ½ÎµÎ¹ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ­Ï‚ Î´Î¹Î±ÏƒÏ„Î¬ÏƒÎµÎ¹Ï‚ Î¼Îµ ÎµÎ¹Î´Î¹ÎºÎ­Ï‚ ÏƒÏ…Î½Î¸Î®ÎºÎµÏ‚, ÏŒÏ€Ï‰Ï‚ Î· Î±Î»Î»Î±Î³Î® Ï€ÏÎ¿Ï€Î¿Î½Î·Ï„Î® ÏƒÏ„Î¿Î½ Î±Î½Ï„Î¯Ï€Î±Î»Î¿.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test questions about Olympiakos vs Panathinaikos derby\n",
        "test_questions = [\n",
        "    \"Î Î¿Î¹Î± ÎµÎ¯Î½Î±Î¹ Î· Î¹ÏƒÏ„Î¿ÏÎ¯Î± Ï„Î¿Ï… Î½Ï„Î­ÏÎ¼Ï€Î¹ ÎŸÎ»Ï…Î¼Ï€Î¹Î±ÎºÏŒÏ‚-Î Î±Î½Î±Î¸Î·Î½Î±ÏŠÎºÏŒÏ‚;\",\n",
        "    \"Î Î¿Î¹Î¿Ï‚ Î­Ï‡ÎµÎ¹ ÎºÎµÏÎ´Î¯ÏƒÎµÎ¹ Ï€ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎµÏ‚ Ï†Î¿ÏÎ­Ï‚ Ï„Î¿ Î½Ï„Î­ÏÎ¼Ï€Î¹;\",\n",
        "    \"Î Î¿Î¹Î± ÎµÎ¯Î½Î±Î¹ Ï„Î± Ï€Î¹Î¿ Î±Î¾Î­Ï‡Î±ÏƒÏ„Î± Î³ÎºÎ¿Î» ÏƒÏ„Î¿ Î½Ï„Î­ÏÎ¼Ï€Î¹;\",\n",
        "    \"Î Î¿Î¹Î¿Î¹ ÎµÎ¯Î½Î±Î¹ Î¿Î¹ ÎºÎ¿ÏÏ…Ï†Î±Î¯Î¿Î¹ Ï€Î±Î¯ÎºÏ„ÎµÏ‚ Ï€Î¿Ï… Î­Ï‡Î¿Ï…Î½ Î±Î³Ï‰Î½Î¹ÏƒÏ„ÎµÎ¯ ÏƒÏ„Î¿ Î½Ï„Î­ÏÎ¼Ï€Î¹;\",\n",
        "    \"Î Î¿Î¹Î± ÎµÎ¯Î½Î±Î¹ Î· ÏƒÎ·Î¼Î±ÏƒÎ¯Î± Ï„Î¿Ï… Î½Ï„Î­ÏÎ¼Ï€Î¹ Î³Î¹Î± Ï„Î¿Ï…Ï‚ Ï†Î¹Î»Î¬Î¸Î»Î¿Ï…Ï‚;\"\n",
        "]\n",
        "\n",
        "print(\"Testing Greek Derby RAG System...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "for i, question in enumerate(test_questions, 1):\n",
        "    print(f\"\\nÎ•ÏÏÏ„Î·ÏƒÎ· {i}: {question}\")\n",
        "    print(\"-\" * 30)\n",
        "    \n",
        "    try:\n",
        "        response = greek_derby_graph.invoke({\"question\": question})\n",
        "        print(f\"Î‘Ï€Î¬Î½Ï„Î·ÏƒÎ·: {response['answer']}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Î£Ï†Î¬Î»Î¼Î±: {e}\")\n",
        "    \n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Interactive Greek Derby Chat\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Î•ÏÏÏ„Î·ÏƒÎ·: Î Î¿Ï… Î³Î¯Î½ÎµÏ„Î±Î¹ Ï„Î¿ Î½Ï„Î­ÏÎ¼Ï€Î¹ ÎŸÎ»Ï…Î¼Ï€Î¹Î±ÎºÏŒÏ‚-Î Î±Î½Î±Î¸Î·Î½Î±ÏŠÎºÏŒÏ‚;\n",
            "Î‘Î½Î±Î¶Î®Ï„Î·ÏƒÎ· Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¹ÏÎ½...\n",
            "\n",
            "Î‘Ï€Î¬Î½Ï„Î·ÏƒÎ·: Î¤Î¿ Î½Ï„Î­ÏÎ¼Ï€Î¹ ÎŸÎ»Ï…Î¼Ï€Î¹Î±ÎºÏŒÏ‚-Î Î±Î½Î±Î¸Î·Î½Î±ÏŠÎºÏŒÏ‚ Î³Î¯Î½ÎµÏ„Î±Î¹ ÏƒÏ…Î½Î®Î¸Ï‰Ï‚ ÏƒÏ„Î¿ Î³Î®Ï€ÎµÎ´Î¿ Ï„Î¿Ï… ÎŸÎ»Ï…Î¼Ï€Î¹Î±ÎºÎ¿Ï, Ï„Î¿ Î“ÎµÏÏÎ³Î¹Î¿Ï‚ ÎšÎ±ÏÎ±ÏŠÏƒÎºÎ¬ÎºÎ·Ï‚, Î® ÏƒÏ„Î¿ Î³Î®Ï€ÎµÎ´Î¿ Ï„Î¿Ï… Î Î±Î½Î±Î¸Î·Î½Î±ÏŠÎºÎ¿Ï, Ï„Î¿ Î‘Ï€ÏŒÏƒÏ„Î¿Î»Î¿Ï‚ ÎÎ¹ÎºÎ¿Î»Î±ÎÎ´Î·Ï‚, Î±Î½Î¬Î»Î¿Î³Î± Î¼Îµ Ï„Î·Î½ Î­Î´ÏÎ± Ï„Î·Ï‚ ÎºÎ¬Î¸Îµ Î¿Î¼Î¬Î´Î±Ï‚.\n",
            "\n",
            "Î Î·Î³Î­Ï‚:\n",
            "1. ÎŸÎ»Ï…Î¼Ï€Î¹Î±ÎºÏŒÏ‚: ÎŸ Î´ÏÏŒÎ¼Î¿Ï‚ Î³Î¹Î± Ï„Î¿ Î½Ï„Î­ÏÎ¼Ï€Î¹ ÎµÎ¯Î½Î±Î¹ Î­Î½Î±Ï‚ ÎºÎ±Î¹ ÎµÎ¹Î´Î¹ÎºÎ¬ Î¿Î¹ Â«Î¼Ï€Î±ÏÎ¿Ï…Ï„Î¿ÎºÎ±Ï€Î½Î¹ÏƒÎ¼Î­Î½Î¿Î¹Â» Ï„Î¿Î½ Î¾Î­ÏÎ¿Ï…Î½ ÎºÎ±Î»Î¬  ...\n",
            "2. ÎŸÎ»Ï…Î¼Ï€Î¹Î±ÎºÏŒÏ‚: ÎŸ Î´ÏÏŒÎ¼Î¿Ï‚ Î³Î¹Î± Ï„Î¿ Î½Ï„Î­ÏÎ¼Ï€Î¹ ÎµÎ¯Î½Î±Î¹ Î­Î½Î±Ï‚ ÎºÎ±Î¹ ÎµÎ¹Î´Î¹ÎºÎ¬ Î¿Î¹ Â«Î¼Ï€Î±ÏÎ¿Ï…Ï„Î¿ÎºÎ±Ï€Î½Î¹ÏƒÎ¼Î­Î½Î¿Î¹Â» Ï„Î¿Î½ Î¾Î­ÏÎ¿Ï…Î½ ÎºÎ±Î»Î¬  ...\n",
            "3. ÎŸÎ»Ï…Î¼Ï€Î¹Î±ÎºÏŒÏ‚: ÎŸ Î´ÏÏŒÎ¼Î¿Ï‚ Î³Î¹Î± Ï„Î¿ Î½Ï„Î­ÏÎ¼Ï€Î¹ ÎµÎ¯Î½Î±Î¹ Î­Î½Î±Ï‚ ÎºÎ±Î¹ ÎµÎ¹Î´Î¹ÎºÎ¬ Î¿Î¹ Â«Î¼Ï€Î±ÏÎ¿Ï…Ï„Î¿ÎºÎ±Ï€Î½Î¹ÏƒÎ¼Î­Î½Î¿Î¹Â» Ï„Î¿Î½ Î¾Î­ÏÎ¿Ï…Î½ ÎºÎ±Î»Î¬  ...\n",
            "4. ÎŸÎ»Ï…Î¼Ï€Î¹Î±ÎºÏŒÏ‚: ÎŸ Î´ÏÏŒÎ¼Î¿Ï‚ Î³Î¹Î± Ï„Î¿ Î½Ï„Î­ÏÎ¼Ï€Î¹ ÎµÎ¯Î½Î±Î¹ Î­Î½Î±Ï‚ ÎºÎ±Î¹ ÎµÎ¹Î´Î¹ÎºÎ¬ Î¿Î¹ Â«Î¼Ï€Î±ÏÎ¿Ï…Ï„Î¿ÎºÎ±Ï€Î½Î¹ÏƒÎ¼Î­Î½Î¿Î¹Â» Ï„Î¿Î½ Î¾Î­ÏÎ¿Ï…Î½ ÎºÎ±Î»Î¬  ...\n"
          ]
        }
      ],
      "source": [
        "def ask_greek_derby_question(question: str):\n",
        "    \"\"\"Interactive function to ask questions about the Greek derby\"\"\"\n",
        "    print(f\"Î•ÏÏÏ„Î·ÏƒÎ·: {question}\")\n",
        "    print(\"Î‘Î½Î±Î¶Î®Ï„Î·ÏƒÎ· Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¹ÏÎ½...\")\n",
        "    \n",
        "    try:\n",
        "        response = greek_derby_graph.invoke({\"question\": question})\n",
        "        print(f\"\\nÎ‘Ï€Î¬Î½Ï„Î·ÏƒÎ·: {response['answer']}\")\n",
        "        \n",
        "        # Show sources\n",
        "        print(\"\\nÎ Î·Î³Î­Ï‚:\")\n",
        "        for i, doc in enumerate(response['context'], 1):\n",
        "            print(f\"{i}. {doc.page_content[:100]}...\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"Î£Ï†Î¬Î»Î¼Î±: {e}\")\n",
        "\n",
        "\n",
        "# Uncomment to test interactive mode\n",
        "ask_greek_derby_question(\"Î Î¿Ï… Î³Î¯Î½ÎµÏ„Î±Î¹ Ï„Î¿ Î½Ï„Î­ÏÎ¼Ï€Î¹ ÎŸÎ»Ï…Î¼Ï€Î¹Î±ÎºÏŒÏ‚-Î Î±Î½Î±Î¸Î·Î½Î±ÏŠÎºÏŒÏ‚;\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Performance Metrics and Monitoring\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Greek RAG benchmark...\n",
            "\n",
            "Benchmark Results:\n",
            "Total Questions: 3\n",
            "Successful Answers: 3\n",
            "Failed Answers: 0\n",
            "Average Response Time: 1.95 seconds\n",
            "Success Rate: 100.0%\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from typing import Dict, Any\n",
        "\n",
        "def benchmark_greek_rag(questions: list) -> Dict[str, Any]:\n",
        "    \"\"\"Benchmark the Greek RAG system performance\"\"\"\n",
        "    results = {\n",
        "        'total_questions': len(questions),\n",
        "        'successful_answers': 0,\n",
        "        'failed_answers': 0,\n",
        "        'average_response_time': 0,\n",
        "        'total_time': 0\n",
        "    }\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    for question in questions:\n",
        "        question_start = time.time()\n",
        "        try:\n",
        "            response = greek_derby_graph.invoke({\"question\": question})\n",
        "            if response['answer']:\n",
        "                results['successful_answers'] += 1\n",
        "            else:\n",
        "                results['failed_answers'] += 1\n",
        "        except Exception as e:\n",
        "            results['failed_answers'] += 1\n",
        "            print(f\"Error with question '{question}': {e}\")\n",
        "        \n",
        "        question_time = time.time() - question_start\n",
        "        results['total_time'] += question_time\n",
        "    \n",
        "    results['average_response_time'] = results['total_time'] / len(questions)\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Run benchmark\n",
        "benchmark_questions = [\n",
        "    \"Î Î¿Î¹Î± ÎµÎ¯Î½Î±Î¹ Î· Î¹ÏƒÏ„Î¿ÏÎ¯Î± Ï„Î¿Ï… Î½Ï„Î­ÏÎ¼Ï€Î¹;\",\n",
        "    \"Î Î¿Î¹Î¿Ï‚ Î­Ï‡ÎµÎ¹ ÎºÎµÏÎ´Î¯ÏƒÎµÎ¹ Ï€ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎµÏ‚ Ï†Î¿ÏÎ­Ï‚;\",\n",
        "    \"Î Î¿Î¹Î± ÎµÎ¯Î½Î±Î¹ Ï„Î± Ï€Î¹Î¿ Î±Î¾Î­Ï‡Î±ÏƒÏ„Î± Î³ÎºÎ¿Î»;\"\n",
        "]\n",
        "\n",
        "print(\"Running Greek RAG benchmark...\")\n",
        "benchmark_results = benchmark_greek_rag(benchmark_questions)\n",
        "\n",
        "print(\"\\nBenchmark Results:\")\n",
        "print(f\"Total Questions: {benchmark_results['total_questions']}\")\n",
        "print(f\"Successful Answers: {benchmark_results['successful_answers']}\")\n",
        "print(f\"Failed Answers: {benchmark_results['failed_answers']}\")\n",
        "print(f\"Average Response Time: {benchmark_results['average_response_time']:.2f} seconds\")\n",
        "print(f\"Success Rate: {(benchmark_results['successful_answers'] / benchmark_results['total_questions']) * 100:.1f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Interactive Greek Derby Chatbot with Memory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ¤– Greek Derby Chatbot initialized with memory!\n",
            "You can now have a conversation about Olympiakos vs Panathinaikos derby.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\PX\\AppData\\Local\\Temp\\ipykernel_10180\\3506290698.py:10: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  self.memory = ConversationBufferMemory(return_messages=True)\n"
          ]
        }
      ],
      "source": [
        "from typing import List, Dict, Any\n",
        "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "class GreekDerbyChatbot:\n",
        "    def __init__(self, rag_graph, llm):\n",
        "        self.rag_graph = rag_graph\n",
        "        self.llm = llm\n",
        "        self.memory = ConversationBufferMemory(return_messages=True)\n",
        "        self.conversation_history = []\n",
        "        \n",
        "        # Enhanced prompt for conversational RAG\n",
        "        self.chat_prompt = ChatPromptTemplate.from_messages([\n",
        "            (\"system\", \"\"\"Î•Î¯ÏƒÏ„Îµ Î­Î½Î±Ï‚ ÎµÎ¾ÎµÎ¹Î´Î¹ÎºÎµÏ…Î¼Î­Î½Î¿Ï‚ Î²Î¿Î·Î¸ÏŒÏ‚ Î³Î¹Î± Ï„Î¿ ÎµÎ»Î»Î·Î½Î¹ÎºÏŒ Ï€Î¿Î´ÏŒÏƒÏ†Î±Î¹ÏÎ¿ ÎºÎ±Î¹ Ï„Î¿ Î½Ï„Î­ÏÎ¼Ï€Î¹ ÎŸÎ»Ï…Î¼Ï€Î¹Î±ÎºÏŒÏ‚-Î Î±Î½Î±Î¸Î·Î½Î±ÏŠÎºÏŒÏ‚.\n",
        "            \n",
        "Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®ÏƒÏ„Îµ Ï„Î¹Ï‚ Ï€Î±ÏÎ±ÎºÎ¬Ï„Ï‰ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ Î³Î¹Î± Î½Î± Î±Ï€Î±Î½Ï„Î®ÏƒÎµÏ„Îµ ÏƒÏ„Î·Î½ ÎµÏÏÏ„Î·ÏƒÎ· Ï„Î¿Ï… Ï‡ÏÎ®ÏƒÏ„Î·.\n",
        "Î‘Î½ Î´ÎµÎ½ Î³Î½Ï‰ÏÎ¯Î¶ÎµÏ„Îµ Ï„Î·Î½ Î±Ï€Î¬Î½Ï„Î·ÏƒÎ·, Ï€ÎµÎ¯Ï„Îµ ÏŒÏ„Î¹ Î´ÎµÎ½ Î³Î½Ï‰ÏÎ¯Î¶ÎµÏ„Îµ.\n",
        "Î‘Ï€Î±Î½Ï„Î®ÏƒÏ„Îµ ÏƒÏ„Î± ÎµÎ»Î»Î·Î½Î¹ÎºÎ¬ Î¼Îµ Ï†Î¹Î»Î¹ÎºÏŒ ÎºÎ±Î¹ ÎµÎ½Î·Î¼ÎµÏÏ‰Ï„Î¹ÎºÏŒ Ï„ÏÏŒÏ€Î¿.\n",
        "ÎšÏÎ±Ï„Î®ÏƒÏ„Îµ Ï„Î¹Ï‚ Î±Ï€Î±Î½Ï„Î®ÏƒÎµÎ¹Ï‚ ÏƒÏ…Î½Î¿Ï€Ï„Î¹ÎºÎ­Ï‚ Î±Î»Î»Î¬ Ï€Î»Î®ÏÎµÎ¹Ï‚.\n",
        "\n",
        "Î ÎµÏÎ¹ÎµÏ‡ÏŒÎ¼ÎµÎ½Î¿: {context}\n",
        "\n",
        "Î ÏÎ¿Î·Î³Î¿ÏÎ¼ÎµÎ½Î· ÏƒÏ…Î½Î¿Î¼Î¹Î»Î¯Î±:\n",
        "{chat_history}\n",
        "\n",
        "Î•ÏÏÏ„Î·ÏƒÎ·: {question}\n",
        "Î‘Ï€Î¬Î½Ï„Î·ÏƒÎ·:\"\"\"),\n",
        "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "            (\"human\", \"{question}\")\n",
        "        ])\n",
        "    \n",
        "    def chat(self, user_input: str) -> str:\n",
        "        \"\"\"Process user input and return chatbot response\"\"\"\n",
        "        try:\n",
        "            # Get relevant context using RAG\n",
        "            rag_response = self.rag_graph.invoke({\"question\": user_input})\n",
        "            context = rag_response.get(\"context\", [])\n",
        "            \n",
        "            # Format context for the prompt\n",
        "            context_text = \"\\n\\n\".join([doc.page_content for doc in context])\n",
        "            \n",
        "            # Get conversation history\n",
        "            chat_history = self.memory.chat_memory.messages\n",
        "            \n",
        "            # Create the prompt\n",
        "            messages = self.chat_prompt.format_messages(\n",
        "                context=context_text,\n",
        "                chat_history=chat_history,\n",
        "                question=user_input\n",
        "            )\n",
        "            \n",
        "            # Get response from LLM\n",
        "            response = self.llm.invoke(messages)\n",
        "            \n",
        "            # Store in memory\n",
        "            self.memory.chat_memory.add_user_message(user_input)\n",
        "            self.memory.chat_memory.add_ai_message(response.content)\n",
        "            \n",
        "            # Store in conversation history\n",
        "            self.conversation_history.append({\n",
        "                \"user\": user_input,\n",
        "                \"bot\": response.content,\n",
        "                \"context_sources\": [doc.metadata.get(\"source\", \"unknown\") for doc in context]\n",
        "            })\n",
        "            \n",
        "            return response.content\n",
        "            \n",
        "        except Exception as e:\n",
        "            error_msg = f\"Î£Ï†Î¬Î»Î¼Î±: {str(e)}\"\n",
        "            self.memory.chat_memory.add_user_message(user_input)\n",
        "            self.memory.chat_memory.add_ai_message(error_msg)\n",
        "            return error_msg\n",
        "    \n",
        "    def get_conversation_history(self) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Get the full conversation history\"\"\"\n",
        "        return self.conversation_history\n",
        "    \n",
        "    def clear_memory(self):\n",
        "        \"\"\"Clear conversation memory\"\"\"\n",
        "        self.memory.clear()\n",
        "        self.conversation_history = []\n",
        "        print(\"Î— Î¼Î½Î®Î¼Î· Ï„Î·Ï‚ ÏƒÏ…Î½Î¿Î¼Î¹Î»Î¯Î±Ï‚ Î´Î¹Î±Î³ÏÎ¬Ï†Î·ÎºÎµ.\")\n",
        "    \n",
        "    def get_memory_summary(self) -> str:\n",
        "        \"\"\"Get a summary of the conversation\"\"\"\n",
        "        if not self.conversation_history:\n",
        "            return \"Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Î¹ÏƒÏ„Î¿ÏÎ¹ÎºÏŒ ÏƒÏ…Î½Î¿Î¼Î¹Î»Î¯Î±Ï‚.\"\n",
        "        \n",
        "        summary = f\"Î£Ï…Î½Î¿Î¼Î¹Î»Î¯Î± Î¼Îµ {len(self.conversation_history)} ÎµÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚:\\n\"\n",
        "        for i, conv in enumerate(self.conversation_history, 1):\n",
        "            summary += f\"{i}. Î•ÏÏÏ„Î·ÏƒÎ·: {conv['user'][:50]}...\\n\"\n",
        "            summary += f\"   Î‘Ï€Î¬Î½Ï„Î·ÏƒÎ·: {conv['bot'][:50]}...\\n\"\n",
        "        \n",
        "        return summary\n",
        "\n",
        "# Initialize the chatbot\n",
        "chatbot = GreekDerbyChatbot(greek_derby_graph, llm)\n",
        "print(\"ğŸ¤– Greek Derby Chatbot initialized with memory!\")\n",
        "print(\"You can now have a conversation about Olympiakos vs Panathinaikos derby.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "ğŸš€ CHATBOT READY! Choose your interaction mode:\n",
            "==================================================\n",
            "1. For interactive chat, run: interactive_chat()\n",
            "2. For quick questions, run: quick_chat('Your question in Greek')\n",
            "3. Example: quick_chat('Î Î¿Î¹Î± ÎµÎ¯Î½Î±Î¹ Î· Î¹ÏƒÏ„Î¿ÏÎ¯Î± Ï„Î¿Ï… Î½Ï„Î­ÏÎ¼Ï€Î¹;')\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# Interactive Chat Function\n",
        "def interactive_chat():\n",
        "    \"\"\"Interactive chat function for the Greek Derby Chatbot\"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"ğŸ¤– GREEK DERBY CHATBOT - Interactive Mode\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"Type your questions in Greek about Olympiakos vs Panathinaikos derby\")\n",
        "    print(\"Commands:\")\n",
        "    print(\"  - Type 'quit' or 'exit' to end the conversation\")\n",
        "    print(\"  - Type 'history' to see conversation history\")\n",
        "    print(\"  - Type 'clear' to clear memory\")\n",
        "    print(\"  - Type 'help' for more commands\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    while True:\n",
        "        try:\n",
        "            # Get user input\n",
        "            user_input = input(\"\\nğŸ‘¤ You: \").strip()\n",
        "            \n",
        "            # Handle special commands\n",
        "            if user_input.lower() in ['quit', 'exit', 'q']:\n",
        "                print(\"\\nğŸ‘‹ Goodbye! Thanks for chatting about the Greek derby!\")\n",
        "                break\n",
        "            elif user_input.lower() == 'history':\n",
        "                print(\"\\nğŸ“š Conversation History:\")\n",
        "                print(chatbot.get_memory_summary())\n",
        "                continue\n",
        "            elif user_input.lower() == 'clear':\n",
        "                chatbot.clear_memory()\n",
        "                continue\n",
        "            elif user_input.lower() == 'help':\n",
        "                print(\"\\nğŸ†˜ Available Commands:\")\n",
        "                print(\"  - Ask any question about Olympiakos vs Panathinaikos\")\n",
        "                print(\"  - 'history' - Show conversation history\")\n",
        "                print(\"  - 'clear' - Clear conversation memory\")\n",
        "                print(\"  - 'quit' or 'exit' - End conversation\")\n",
        "                continue\n",
        "            elif not user_input:\n",
        "                print(\"Please enter a question or command.\")\n",
        "                continue\n",
        "            \n",
        "            # Get chatbot response\n",
        "            print(\"\\nğŸ¤– Bot: \", end=\"\")\n",
        "            response = chatbot.chat(user_input)\n",
        "            print(response)\n",
        "            \n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\n\\nğŸ‘‹ Goodbye! Thanks for chatting about the Greek derby!\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"\\nâŒ Error: {e}\")\n",
        "            print(\"Please try again or type 'quit' to exit.\")\n",
        "\n",
        "# Quick chat function for single questions\n",
        "def quick_chat(question: str):\n",
        "    \"\"\"Quick chat function for single questions\"\"\"\n",
        "    print(f\"ğŸ‘¤ You: {question}\")\n",
        "    response = chatbot.chat(question)\n",
        "    print(f\"ğŸ¤– Bot: {response}\")\n",
        "    return response\n",
        "\n",
        "# Example usage and demo\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"ğŸš€ CHATBOT READY! Choose your interaction mode:\")\n",
        "print(\"=\"*50)\n",
        "print(\"1. For interactive chat, run: interactive_chat()\")\n",
        "print(\"2. For quick questions, run: quick_chat('Your question in Greek')\")\n",
        "print(\"3. Example: quick_chat('Î Î¿Î¹Î± ÎµÎ¯Î½Î±Î¹ Î· Î¹ÏƒÏ„Î¿ÏÎ¯Î± Ï„Î¿Ï… Î½Ï„Î­ÏÎ¼Ï€Î¹;')\")\n",
        "print(\"=\"*50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ¯ DEMO: Testing the Greek Derby Chatbot\n",
            "==================================================\n",
            "Testing with sample questions...\n",
            "\n",
            "Demo Question 1:\n",
            "ğŸ‘¤ You: Î Î¿Î¹Î± ÎµÎ¯Î½Î±Î¹ Î· Î¹ÏƒÏ„Î¿ÏÎ¯Î± Ï„Î¿Ï… Î½Ï„Î­ÏÎ¼Ï€Î¹;\n",
            "ğŸ¤– Bot: Î— Î¹ÏƒÏ„Î¿ÏÎ¯Î± Ï„Î¿Ï… Î½Ï„Î­ÏÎ¼Ï€Î¹ ÎŸÎ»Ï…Î¼Ï€Î¹Î±ÎºÏŒÏ‚ - Î Î±Î½Î±Î¸Î·Î½Î±ÏŠÎºÏŒÏ‚ ÎµÎ¯Î½Î±Î¹ Ï€Î»Î¿ÏÏƒÎ¹Î± ÎºÎ±Î¹ Î³ÎµÎ¼Î¬Ï„Î· Ï€Î¬Î¸Î¿Ï‚. Î ÏÏŒÎºÎµÎ¹Ï„Î±Î¹ Î³Î¹Î± Î­Î½Î±Î½ Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Ï€Î¹Î¿ ÏƒÎ·Î¼Î±Î½Ï„Î¹ÎºÎ¿ÏÏ‚ ÎºÎ±Î¹ Î¹ÏƒÏ„Î¿ÏÎ¹ÎºÎ¿ÏÏ‚ Î±Î³ÏÎ½ÎµÏ‚ Ï„Î¿Ï… ÎµÎ»Î»Î·Î½Î¹ÎºÎ¿Ï Ï€Î¿Î´Î¿ÏƒÏ†Î±Î¯ÏÎ¿Ï…, Ï€Î¿Ï… Î­Ï‡ÎµÎ¹ Î¾ÎµÎºÎ¹Î½Î®ÏƒÎµÎ¹ Î±Ï€ÏŒ Ï„Î· Î´ÎµÎºÎ±ÎµÏ„Î¯Î± Ï„Î¿Ï… 1920. ÎŸÎ¹ Î´ÏÎ¿ Î¿Î¼Î¬Î´ÎµÏ‚ ÎµÎ¯Î½Î±Î¹ Î±Ï€ÏŒ Ï„Î¹Ï‚ Ï€Î¹Î¿ ÎµÏ€Î¹Ï„Ï…Ï‡Î·Î¼Î­Î½ÎµÏ‚ ÏƒÏ„Î·Î½ Î•Î»Î»Î¬Î´Î± ÎºÎ±Î¹ Ï„Î¿ Î½Ï„Î­ÏÎ¼Ï€Î¹ Î±Ï€Î¿Ï„ÎµÎ»ÎµÎ¯ ÏƒÎ·Î¼ÎµÎ¯Î¿ Î±Î½Î±Ï†Î¿ÏÎ¬Ï‚ Î³Î¹Î± Ï„Î¿Ï…Ï‚ Ï†Î¹Î»Î¬Î¸Î»Î¿Ï…Ï‚ Ï„Î¿Ï…Ï‚.\n",
            "\n",
            "ÎœÎ­Ï‡ÏÎ¹ ÏƒÎ®Î¼ÎµÏÎ±, Î¿Î¹ Î±Î³ÏÎ½ÎµÏ‚ Î±Ï…Ï„Î¿Î¯ Î­Ï‡Î¿Ï…Î½ Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„ÎµÎ¯ Î±Ï€ÏŒ Î­Î½Ï„Î¿Î½Î¿ Î±Î½Ï„Î±Î³Ï‰Î½Î¹ÏƒÎ¼ÏŒ, Î¹ÏƒÏ„Î¿ÏÎ¹ÎºÎ¬ Ï€ÎµÏÎ¹ÏƒÏ„Î±Ï„Î¹ÎºÎ¬ ÎºÎ±Î¹ Ï€Î¿Î»Î»Î­Ï‚ Î±Î½Î±Ï„ÏÎ¿Ï€Î­Ï‚. Î¤Î¿ Î½Ï„Î­ÏÎ¼Ï€Î¹ Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ Î¼ÏŒÎ½Î¿ Î±Î¸Î»Î·Ï„Î¹ÎºÎ® Î±Î½Î±Î¼Î­Ï„ÏÎ·ÏƒÎ·, Î±Î»Î»Î¬ ÎºÎ±Î¹ ÎºÎ¿Î¹Î½Ï‰Î½Î¹ÎºÏŒ Ï†Î±Î¹Î½ÏŒÎ¼ÎµÎ½Î¿, Î¼Îµ Ï„Î¿Ï…Ï‚ Ï†Î¹Î»Î¬Î¸Î»Î¿Ï…Ï‚ Î½Î± Î¶Î¿Ï…Î½ ÎºÎ¬Î¸Îµ Î±Î³ÏÎ½Î± Î¼Îµ Î¼ÎµÎ³Î¬Î»Î· Î­Î½Ï„Î±ÏƒÎ· ÎºÎ±Î¹ Î±Ï†Î¿ÏƒÎ¯Ï‰ÏƒÎ·. \n",
            "\n",
            "Î— ÎºÏŒÎ½Ï„ÏÎ± Î­Ï‡ÎµÎ¹ Î±Î½Î±Î´ÎµÎ¯Î¾ÎµÎ¹ Ï€Î¿Î»Î»Î­Ï‚ ÏƒÏ€Î¿Ï…Î´Î±Î¯ÎµÏ‚ Ï€ÏÎ¿ÏƒÏ‰Ï€Î¹ÎºÏŒÏ„Î·Ï„ÎµÏ‚ ÎºÎ±Î¹ ÏƒÏ„Î¹Î³Î¼Î­Ï‚ ÏƒÏ„Î¿Î½ ÎµÎ»Î»Î·Î½Î¹ÎºÏŒ Ï€Î¿Î´ÏŒÏƒÏ†Î±Î¹ÏÎ¿, Î¼Îµ ÎµÎ¾Î­Ï‡Î¿Ï…ÏƒÎµÏ‚ Î½Î¯ÎºÎµÏ‚ ÎºÎ±Î¹ ÏƒÎ·Î¼Î±Î½Ï„Î¹ÎºÎ¿ÏÏ‚ Ï„Î¯Ï„Î»Î¿Ï…Ï‚ Î½Î± ÎºÏÎ¯Î½ÎµÏ„Î±Î¹ ÏƒÎµ Î±Ï…Ï„Î­Ï‚ Ï„Î¹Ï‚ Î±Î½Î±Î¼ÎµÏ„ÏÎ®ÏƒÎµÎ¹Ï‚. Î£Î®Î¼ÎµÏÎ±, Ï„Î¿ Î½Ï„Î­ÏÎ¼Ï€Î¹ Ï€Î±ÏÎ±Î¼Î­Î½ÎµÎ¹ Î¼Î¹Î± Î±Ï€ÏŒ Ï„Î¹Ï‚ Ï€Î¹Î¿ Î±Î½Î±Î¼ÎµÎ½ÏŒÎ¼ÎµÎ½ÎµÏ‚ Ï€Ï„Ï…Ï‡Î­Ï‚ Ï„Î¿Ï… ÎµÎ»Î»Î·Î½Î¹ÎºÎ¿Ï Ï€Î¿Î´Î¿ÏƒÏ†Î±Î¯ÏÎ¿Ï…, Î¼Îµ Ï„Î·Î½ Î±Ï„Î¼ÏŒÏƒÏ†Î±Î¹ÏÎ± ÎºÎ±Î¹ Ï„Î·Î½ Î­Î½Ï„Î±ÏƒÎ· Î½Î± ÎµÎ¯Î½Î±Î¹ Ï€Î¬Î½Ï„Î± ÏƒÏ„Î¿ Ï…ÏˆÎ·Î»ÏŒÏ„ÎµÏÎ¿ ÎµÏ€Î¯Ï€ÎµÎ´Î¿.\n",
            "----------------------------------------\n",
            "Demo Question 2:\n",
            "ğŸ‘¤ You: Î Î¿Î¹Î¿Ï‚ Î­Ï‡ÎµÎ¹ ÎºÎµÏÎ´Î¯ÏƒÎµÎ¹ Ï€ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎµÏ‚ Ï†Î¿ÏÎ­Ï‚;\n",
            "ğŸ¤– Bot: Î”ÎµÎ½ Î³Î½Ï‰ÏÎ¯Î¶Ï‰ Ï€Î¿Î¹Î¿Ï‚ Î­Ï‡ÎµÎ¹ ÎºÎµÏÎ´Î¯ÏƒÎµÎ¹ Ï€ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎµÏ‚ Ï†Î¿ÏÎ­Ï‚ Ï„Î¿ Î½Ï„Î­ÏÎ¼Ï€Î¹ ÎŸÎ»Ï…Î¼Ï€Î¹Î±ÎºÏŒÏ‚ - Î Î±Î½Î±Î¸Î·Î½Î±ÏŠÎºÏŒÏ‚.\n",
            "----------------------------------------\n",
            "Demo Question 3:\n",
            "ğŸ‘¤ You: Î Î¿Î¹Î¿Î¹ ÎµÎ¯Î½Î±Î¹ Î¿Î¹ ÎºÎ¿ÏÏ…Ï†Î±Î¯Î¿Î¹ Ï€Î±Î¯ÎºÏ„ÎµÏ‚;\n",
            "ğŸ¤– Bot: ÎŸÎ¹ ÎºÎ¿ÏÏ…Ï†Î±Î¯Î¿Î¹ Ï€Î±Î¯ÎºÏ„ÎµÏ‚ ÏƒÏ„Î·Î½ Î¹ÏƒÏ„Î¿ÏÎ¯Î± Ï„Ï‰Î½ Î´ÏÎ¿ Î¿Î¼Î¬Î´Ï‰Î½, ÎŸÎ»Ï…Î¼Ï€Î¹Î±ÎºÏŒ ÎºÎ±Î¹ Î Î±Î½Î±Î¸Î·Î½Î±ÏŠÎºÏŒ, ÎµÎ¯Î½Î±Î¹ Ï€Î¿Î»Î»Î¿Î¯ ÎºÎ±Î¹ Ï€Î¿Î¹ÎºÎ¯Î»Î¿Î¹. Î‘Ï€ÏŒ Ï„Î¿Î½ ÎŸÎ»Ï…Î¼Ï€Î¹Î±ÎºÏŒ, Î¾ÎµÏ‡Ï‰ÏÎ¯Î¶Î¿Ï…Î½ Î¿ Î‘Î»Î­Î¾Î·Ï‚ Î‘Î»ÎµÎ¾Î±Î½Î´ÏÎ®Ï‚, Î¿Ï€Î¿Î¯Î¿Ï‚ ÎµÎ¯Î½Î±Î¹ Î¿ Ï€ÏÏÏ„Î¿Ï‚ ÏƒÎºÏŒÏÎµÏ ÏƒÏ„Î·Î½ Î¹ÏƒÏ„Î¿ÏÎ¯Î± Ï„Î¿Ï… ÏƒÏ…Î»Î»ÏŒÎ³Î¿Ï…, ÎºÎ±Î¹ Î¿ Î ÏÎ­Î½Ï„ÏÎ±Î³Îº Î¤Î¶ÏŒÏÏ„Î¶ÎµÎ²Î¹Ï„Ï‚. Î‘Ï€ÏŒ Ï„Î¿Î½ Î Î±Î½Î±Î¸Î·Î½Î±ÏŠÎºÏŒ, ÏƒÎ·Î¼Î±Î½Ï„Î¹ÎºÎ­Ï‚ Ï†Î¹Î³Î¿ÏÏÎµÏ‚ Î±Ï€Î¿Ï„ÎµÎ»Î¿ÏÎ½ Î¿Î¹ ÏƒÏ€Î¿Ï…Î´Î±Î¯Î¿Î¹ Ï€Î±Î¯ÎºÏ„ÎµÏ‚ ÏŒÏ€Ï‰Ï‚ Î¿ Î“Î¹ÏÏÎ³Î¿Ï‚ ÎšÎ±ÏÎ±Î³ÎºÎ¿ÏÎ½Î·Ï‚ ÎºÎ±Î¹ Î¿ Î”Î·Î¼Î®Ï„ÏÎ·Ï‚ Î£Î±ÏÎ±Î²Î¬ÎºÎ¿Ï‚. \n",
            "\n",
            "Î— Î»Î¯ÏƒÏ„Î± Î¼Îµ Ï„Î¿Ï…Ï‚ ÎºÎ¿ÏÏ…Ï†Î±Î¯Î¿Ï…Ï‚ Ï€Î±Î¯ÎºÏ„ÎµÏ‚ Ï€ÎµÏÎ¹Î»Î±Î¼Î²Î¬Î½ÎµÎ¹ ÎµÏ€Î¯ÏƒÎ·Ï‚ Ï€Î¿Î»Î»Î¿ÏÏ‚ Î¬Î»Î»Î¿Ï…Ï‚ ÏƒÏ€Î¿Ï…Î´Î±Î¯Î¿Ï…Ï‚ Î±Î¸Î»Î·Ï„Î­Ï‚ Ï€Î¿Ï… Î­Ï‡Î¿Ï…Î½ Î´Î¹Î±ÎºÏÎ¹Î¸ÎµÎ¯ Î¼Îµ Ï„Î·Î½ ÎµÏÏ…Î¸ÏÏŒÎ»ÎµÏ…ÎºÎ· ÎºÎ±Î¹ Ï„Î·Î½ Ï€ÏÎ¬ÏƒÎ¹Î½Î· Ï†Î±Î½Î­Î»Î±. ÎšÎ¬Î¸Îµ ÎµÏ€Î¿Ï‡Î® Î­Ï‡ÎµÎ¹ Ï„Î¿Ï…Ï‚ Î´Î¹ÎºÎ¿ÏÏ‚ Ï„Î·Ï‚ Î±ÏƒÏ„Î­ÏÎµÏ‚ ÎºÎ±Î¹ Î±Î¾Î­Ï‡Î±ÏƒÏ„ÎµÏ‚ Ï€ÏÎ¿ÏƒÏ‰Ï€Î¹ÎºÏŒÏ„Î·Ï„ÎµÏ‚ Ï€Î¿Ï… Î­Ï‡Î¿Ï…Î½ Î±Ï†Î®ÏƒÎµÎ¹ Ï„Î· ÏƒÏ†ÏÎ±Î³Î¯Î´Î± Ï„Î¿Ï…Ï‚ ÏƒÏ„Î¿ ÎµÎ»Î»Î·Î½Î¹ÎºÏŒ Ï€Î¿Î´ÏŒÏƒÏ†Î±Î¹ÏÎ¿.\n",
            "----------------------------------------\n",
            "\n",
            "âœ… Demo completed! The chatbot is ready for interactive use.\n",
            "\n",
            "============================================================\n",
            "ğŸš€ READY TO CHAT! Choose your option:\n",
            "============================================================\n",
            "1. Run: interactive_chat()  # For full interactive mode\n",
            "2. Run: quick_chat('Your question')  # For single questions\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Demo: Test the chatbot with sample questions\n",
        "print(\"ğŸ¯ DEMO: Testing the Greek Derby Chatbot\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Test questions in Greek\n",
        "demo_questions = [\n",
        "    \"Î Î¿Î¹Î± ÎµÎ¯Î½Î±Î¹ Î· Î¹ÏƒÏ„Î¿ÏÎ¯Î± Ï„Î¿Ï… Î½Ï„Î­ÏÎ¼Ï€Î¹;\",\n",
        "    \"Î Î¿Î¹Î¿Ï‚ Î­Ï‡ÎµÎ¹ ÎºÎµÏÎ´Î¯ÏƒÎµÎ¹ Ï€ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎµÏ‚ Ï†Î¿ÏÎ­Ï‚;\",\n",
        "    \"Î Î¿Î¹Î¿Î¹ ÎµÎ¯Î½Î±Î¹ Î¿Î¹ ÎºÎ¿ÏÏ…Ï†Î±Î¯Î¿Î¹ Ï€Î±Î¯ÎºÏ„ÎµÏ‚;\"\n",
        "]\n",
        "\n",
        "print(\"Testing with sample questions...\\n\")\n",
        "\n",
        "for i, question in enumerate(demo_questions, 1):\n",
        "    print(f\"Demo Question {i}:\")\n",
        "    response = quick_chat(question)\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "print(\"\\nâœ… Demo completed! The chatbot is ready for interactive use.\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸš€ READY TO CHAT! Choose your option:\")\n",
        "print(\"=\"*60)\n",
        "print(\"1. Run: interactive_chat()  # For full interactive mode\")\n",
        "print(\"2. Run: quick_chat('Your question')  # For single questions\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Advanced Chatbot Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”§ Advanced features available:\n",
            "- get_chatbot_stats() - View conversation statistics\n",
            "- export_conversation() - Export chat to JSON file\n",
            "- chatbot.clear_memory() - Clear conversation memory\n",
            "- chatbot.get_conversation_history() - Get full history\n"
          ]
        }
      ],
      "source": [
        "# Advanced chatbot features\n",
        "def get_chatbot_stats():\n",
        "    \"\"\"Get statistics about the chatbot conversation\"\"\"\n",
        "    history = chatbot.get_conversation_history()\n",
        "    if not history:\n",
        "        return \"No conversation yet.\"\n",
        "    \n",
        "    total_questions = len(history)\n",
        "    total_chars = sum(len(conv['user']) + len(conv['bot']) for conv in history)\n",
        "    avg_question_length = sum(len(conv['user']) for conv in history) / total_questions\n",
        "    avg_answer_length = sum(len(conv['bot']) for conv in history) / total_questions\n",
        "    \n",
        "    return f\"\"\"\n",
        "ğŸ“Š Chatbot Statistics:\n",
        "- Total Questions: {total_questions}\n",
        "- Total Characters: {total_chars:,}\n",
        "- Avg Question Length: {avg_question_length:.1f} chars\n",
        "- Avg Answer Length: {avg_answer_length:.1f} chars\n",
        "\"\"\"\n",
        "\n",
        "def export_conversation(filename=\"greek_derby_chat.json\"):\n",
        "    \"\"\"Export conversation to JSON file\"\"\"\n",
        "    import json\n",
        "    history = chatbot.get_conversation_history()\n",
        "    with open(filename, 'w', encoding='utf-8') as f:\n",
        "        json.dump(history, f, ensure_ascii=False, indent=2)\n",
        "    print(f\"Conversation exported to {filename}\")\n",
        "\n",
        "print(\"ğŸ”§ Advanced features available:\")\n",
        "print(\"- get_chatbot_stats() - View conversation statistics\")\n",
        "print(\"- export_conversation() - Export chat to JSON file\")\n",
        "print(\"- chatbot.clear_memory() - Clear conversation memory\")\n",
        "print(\"- chatbot.get_conversation_history() - Get full history\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "music-chatbot",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
