# ğŸ‡¬ğŸ‡· Greek Derby RAG Chatbot - Backend

A sophisticated RAG (Retrieval-Augmented Generation) chatbot system that provides real-time information about the Greek football derby between Olympiakos and Panathinaikos, powered by content from [Gazzetta.gr](https://www.gazzetta.gr/).

## ğŸš€ Features

### **Real-time Content Integration**
- **Gazzetta.gr Scraping**: Automatically fetches latest news and information from Greece's premier sports website
- **Multi-source Data**: Loads content from Olympiakos, Panathinaikos, and general Super League pages
- **Intelligent Fallback**: Falls back to sample content if web scraping fails
- **Respectful Scraping**: Implements delays and proper user agents to respect the website

### **Advanced RAG Architecture**
- **Vector Database**: Uses Pinecone for efficient similarity search
- **OpenAI Integration**: GPT-4o-mini for intelligent responses
- **Embeddings**: text-embedding-3-small for high-quality vector representations
- **LangGraph**: Sophisticated graph-based RAG pipeline
- **Memory System**: Conversation history and context awareness

### **API Endpoints**
- **FastAPI Backend**: Modern, fast API with automatic documentation
- **CORS Support**: Ready for frontend integration
- **Health Monitoring**: Built-in health checks and status endpoints
- **Export Functionality**: Conversation export and statistics

## ğŸ—ï¸ Architecture

```
Backend/
â”œâ”€â”€ api/
â”‚   â””â”€â”€ greek_derby_api.py          # FastAPI web server
â”œâ”€â”€ standalone-service/
â”‚   â””â”€â”€ greek_derby_chatbot.py      # Core RAG chatbot
â””â”€â”€ README.md                       # This file
```

### **Core Components**

1. **GreekDerbyChatbot** (`standalone-service/`)
   - Main RAG system with LangGraph
   - Gazzetta.gr content loading
   - Conversation memory management
   - Vector database operations

2. **FastAPI Server** (`api/`)
   - RESTful API endpoints
   - CORS middleware
   - Error handling
   - Request/response models

## ğŸ“‹ Prerequisites

### **Required Environment Variables**
Create a `.env` file in the project root with:

```env
# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here

# Pinecone Configuration
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_GREEK_DERBY_INDEX_NAME=your_index_name_here

# Optional: User Agent for web scraping
USER_AGENT=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36
```

### **Python Dependencies**
```bash
pip install -r requirements_api.txt
```

### **Required Packages**
- `langchain` - RAG framework
- `langchain-openai` - OpenAI integration
- `langchain-pinecone` - Vector database
- `langchain-community` - Web scraping
- `langgraph` - Graph-based RAG
- `fastapi` - Web API framework
- `uvicorn` - ASGI server
- `pinecone-client` - Vector database client
- `beautifulsoup4` - HTML parsing
- `requests` - HTTP requests
- `python-dotenv` - Environment variables

## ğŸš€ Quick Start

### **1. Standalone Chatbot**
```bash
cd backend/standalone-service
python greek_derby_chatbot.py
```

### **2. API Server**
```bash
cd backend/api
python greek_derby_api.py
```

### **3. Using uvicorn directly**
```bash
cd backend/api
uvicorn greek_derby_api:app --host 0.0.0.0 --port 8000 --reload
```

## ğŸ“¡ API Endpoints

### **Core Endpoints**

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/` | API information and available endpoints |
| `GET` | `/health` | Health check and system status |
| `POST` | `/chat` | Send message to chatbot |
| `GET` | `/history` | Get conversation history |
| `GET` | `/stats` | Get conversation statistics |
| `POST` | `/clear` | Clear conversation memory |
| `GET` | `/export` | Export conversation to JSON |
| `GET` | `/sample-questions` | Get sample questions |

### **Example API Usage**

```python
import requests

# Send a message
response = requests.post('http://localhost:8000/chat', 
                        json={'question': 'Î Î¿Î¹Î± ÎµÎ¯Î½Î±Î¹ Î· Î¹ÏƒÏ„Î¿ÏÎ¯Î± Ï„Î¿Ï… Î½Ï„Î­ÏÎ¼Ï€Î¹;'})
print(response.json())

# Get conversation history
history = requests.get('http://localhost:8000/history')
print(history.json())

# Get statistics
stats = requests.get('http://localhost:8000/stats')
print(stats.json())
```

## ğŸ”„ Gazzetta.gr Integration

### **Content Sources**
The system automatically loads content from:

1. **Olympiakos Page**: `https://www.gazzetta.gr/football/superleague/olympiakos`
2. **Panathinaikos Page**: `https://www.gazzetta.gr/football/superleague/panathinaikos`
3. **Super League Page**: `https://www.gazzetta.gr/football/superleague`
4. **Main Gazzetta Page**: `https://www.gazzetta.gr`

### **Content Processing**
- **Smart Scraping**: Uses multiple CSS selectors to extract relevant content
- **Fallback Methods**: If primary scraping fails, tries alternative approaches
- **Content Filtering**: Removes short or irrelevant content
- **Greek-friendly Splitting**: Uses Greek language separators for optimal chunking
- **Metadata Enrichment**: Adds source URLs and content type information

### **Scraping Strategy**
```python
# Primary method: WebBaseLoader with CSS selectors
loader = WebBaseLoader(
    web_paths=(url,),
    bs_kwargs=dict(
        parse_only=bs4.SoupStrainer(
            class_=("article-content", "article-title", "content", ...)
        )
    ),
)

# Fallback method: No selectors
loader_fallback = WebBaseLoader(web_paths=(url,))

# Last resort: Direct requests
response = requests.get(url, headers={'User-Agent': user_agent})
```

## ğŸ§  RAG System Details

### **Vector Database**
- **Provider**: Pinecone
- **Embeddings**: OpenAI text-embedding-3-small (1024 dimensions)
- **Chunk Size**: 500 characters with 100 character overlap
- **Similarity Search**: Retrieves top 4 most relevant chunks

### **Language Model**
- **Model**: GPT-4o-mini
- **Provider**: OpenAI
- **Temperature**: Default (balanced creativity/consistency)
- **Max Tokens**: Context-dependent

### **Prompt Engineering**
```python
prompt_template = """
Î•Î¯ÏƒÏ„Îµ Î­Î½Î±Ï‚ ÎµÎ¾ÎµÎ¹Î´Î¹ÎºÎµÏ…Î¼Î­Î½Î¿Ï‚ Î²Î¿Î·Î¸ÏŒÏ‚ Î³Î¹Î± Ï„Î¿ ÎµÎ»Î»Î·Î½Î¹ÎºÏŒ Ï€Î¿Î´ÏŒÏƒÏ†Î±Î¹ÏÎ¿ ÎºÎ±Î¹ Ï„Î¿ Î½Ï„Î­ÏÎ¼Ï€Î¹ ÎŸÎ»Ï…Î¼Ï€Î¹Î±ÎºÏŒÏ‚-Î Î±Î½Î±Î¸Î·Î½Î±ÏŠÎºÏŒÏ‚.

Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®ÏƒÏ„Îµ Ï„Î¹Ï‚ Ï€Î±ÏÎ±ÎºÎ¬Ï„Ï‰ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ Î³Î¹Î± Î½Î± Î±Ï€Î±Î½Ï„Î®ÏƒÎµÏ„Îµ ÏƒÏ„Î·Î½ ÎµÏÏÏ„Î·ÏƒÎ· Ï„Î¿Ï… Ï‡ÏÎ®ÏƒÏ„Î·.
Î‘Î½ Î´ÎµÎ½ Î³Î½Ï‰ÏÎ¯Î¶ÎµÏ„Îµ Ï„Î·Î½ Î±Ï€Î¬Î½Ï„Î·ÏƒÎ·, Ï€ÎµÎ¯Ï„Îµ ÏŒÏ„Î¹ Î´ÎµÎ½ Î³Î½Ï‰ÏÎ¯Î¶ÎµÏ„Îµ.
Î‘Ï€Î±Î½Ï„Î®ÏƒÏ„Îµ ÏƒÏ„Î± ÎµÎ»Î»Î·Î½Î¹ÎºÎ¬ Î¼Îµ Ï†Î¹Î»Î¹ÎºÏŒ ÎºÎ±Î¹ ÎµÎ½Î·Î¼ÎµÏÏ‰Ï„Î¹ÎºÏŒ Ï„ÏÏŒÏ€Î¿.
ÎšÏÎ±Ï„Î®ÏƒÏ„Îµ Ï„Î¹Ï‚ Î±Ï€Î±Î½Ï„Î®ÏƒÎµÎ¹Ï‚ ÏƒÏ…Î½Î¿Ï€Ï„Î¹ÎºÎ­Ï‚ Î±Î»Î»Î¬ Ï€Î»Î®ÏÎµÎ¹Ï‚.

Î ÎµÏÎ¹ÎµÏ‡ÏŒÎ¼ÎµÎ½Î¿: {context}
Î•ÏÏÏ„Î·ÏƒÎ·: {question}
Î‘Ï€Î¬Î½Ï„Î·ÏƒÎ·:"""
```

## ğŸ”§ Configuration

### **Environment Variables**

| Variable | Description | Required |
|----------|-------------|----------|
| `OPENAI_API_KEY` | OpenAI API key for LLM and embeddings | âœ… |
| `PINECONE_API_KEY` | Pinecone API key for vector database | âœ… |
| `PINECONE_GREEK_DERBY_INDEX_NAME` | Pinecone index name | âœ… |
| `USER_AGENT` | User agent for web scraping | âŒ |

### **Customization Options**

```python
# Chunk size and overlap
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,        # Adjust based on content
    chunk_overlap=100,     # Adjust for context preservation
    separators=["\n\n", "\n", ". ", "! ", "? ", " ", ""]
)

# Number of retrieved documents
retrieved_docs = vector_store.similarity_search(
    question, 
    k=4  # Adjust based on needs
)

# Embedding dimensions
embeddings = OpenAIEmbeddings(
    model="text-embedding-3-small",
    dimensions=1024  # Can be 1536 or 3072
)
```

## ğŸ› Troubleshooting

### **Common Issues**

1. **"No knowledge base found"**
   - **Cause**: Pinecone index is empty
   - **Solution**: The system will automatically load Gazzetta.gr content

2. **"Failed to load content from Gazzetta.gr"**
   - **Cause**: Network issues or website changes
   - **Solution**: System falls back to sample content automatically

3. **"Missing environment variables"**
   - **Cause**: Required API keys not set
   - **Solution**: Check your `.env` file and environment variables

4. **"Import errors"**
   - **Cause**: Missing dependencies
   - **Solution**: Run `pip install -r requirements_api.txt`

### **Debug Mode**
```python
# Enable debug logging
import logging
logging.basicConfig(level=logging.DEBUG)

# Check Pinecone index stats
stats = index.describe_index_stats()
print(f"Total vectors: {stats['total_vector_count']}")
```

## ğŸ“Š Performance

### **Expected Performance**
- **Initial Load**: 30-60 seconds (depends on Gazzetta.gr response time)
- **Query Response**: 2-5 seconds per question
- **Memory Usage**: ~200-500MB depending on content size
- **Vector Storage**: ~1-5MB for typical content

### **Optimization Tips**
- Use smaller chunk sizes for faster retrieval
- Adjust `k` parameter for similarity search
- Monitor Pinecone usage and costs
- Consider caching for frequently asked questions

## ğŸ”’ Security

### **API Security**
- **CORS**: Configured for frontend integration
- **Input Validation**: Pydantic models for request validation
- **Error Handling**: Graceful error responses without sensitive data

### **Data Privacy**
- **No Personal Data**: System doesn't store personal information
- **Conversation History**: Stored locally, not in external databases
- **API Keys**: Use environment variables, never hardcode

## ğŸ¤ Contributing

### **Adding New Content Sources**
1. Add URLs to `greek_derby_urls` list
2. Test scraping with new selectors if needed
3. Update metadata handling if required

### **Improving Prompts**
1. Modify prompt templates in `_init_rag_system()`
2. Test with various question types
3. Consider adding few-shot examples

### **Enhancing Scraping**
1. Add new CSS selectors for better content extraction
2. Implement content filtering for better quality
3. Add support for other Greek sports websites

## ğŸ“š Additional Resources

- [LangChain Documentation](https://python.langchain.com/)
- [Pinecone Documentation](https://docs.pinecone.io/)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Gazzetta.gr](https://www.gazzetta.gr/) - Source website

