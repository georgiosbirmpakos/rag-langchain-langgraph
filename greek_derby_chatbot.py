"""
Greek Derby RAG Chatbot
A standalone interactive chatbot about Olympiakos vs Panathinaikos derby
using RAG (Retrieval-Augmented Generation) with memory.
"""

import os
import sys
import json
from typing import List, Dict, Any
from datetime import datetime

# LangChain imports
from langchain.chat_models import init_chat_model
from langchain_openai import OpenAIEmbeddings
from langchain_pinecone import PineconeVectorStore
from langchain_core.documents import Document
from langchain.memory import ConversationBufferMemory
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain.prompts import PromptTemplate
from langgraph.graph import StateGraph, START, END
from typing_extensions import TypedDict

# Web scraping imports
from langchain_community.document_loaders import WebBaseLoader

# Pinecone
from pinecone import Pinecone

class GreekDerbyState(TypedDict):
    question: str
    context: List[Document]
    answer: str

class GreekDerbyChatbot:
    """Interactive RAG chatbot for Greek Derby discussions"""
    
    def __init__(self):
        """Initialize the chatbot with all necessary components"""
        print("ğŸš€ Initializing Greek Derby RAG Chatbot...")
        
        # Load environment variables
        self._load_environment()
        
        # Initialize components
        self._init_llm()
        self._init_embeddings()
        self._init_vector_store()
        self._init_rag_system()
        self._init_memory()
        
        # Load or create knowledge base
        self._load_knowledge_base()
        
        print("âœ… Greek Derby Chatbot initialized successfully!")
    
    def _load_environment(self):
        """Load environment variables"""
        try:
            from dotenv import load_dotenv
            load_dotenv()
        except ImportError:
            print("âš ï¸  python-dotenv not installed. Make sure to set environment variables manually.")
        
        # Check required environment variables
        required_vars = ['OPENAI_API_KEY', 'PINECONE_API_KEY', 'PINECONE_GREEK_DERBY_INDEX_NAME']
        missing_vars = [var for var in required_vars if not os.getenv(var)]
        
        if missing_vars:
            print(f"âŒ Missing environment variables: {', '.join(missing_vars)}")
            print("Please set these variables in your .env file or environment")
            sys.exit(1)
        
        print("âœ… Environment variables loaded")
    
    def _init_llm(self):
        """Initialize the language model"""
        self.llm = init_chat_model("gpt-4o-mini", model_provider="openai")
        print("âœ… Language model initialized")
    
    def _init_embeddings(self):
        """Initialize embeddings model"""
        self.embeddings = OpenAIEmbeddings(
            model="text-embedding-3-small",
            dimensions=1024
        )
        print("âœ… Embeddings model initialized")
    
    def _init_vector_store(self):
        """Initialize vector store"""
        pc = Pinecone(api_key=os.getenv('PINECONE_API_KEY'))
        self.index = pc.Index(os.getenv('PINECONE_INDEX_NAME'))
        self.vector_store = PineconeVectorStore(embedding=self.embeddings, index=self.index)
        print("âœ… Vector store initialized")
    
    def _init_rag_system(self):
        """Initialize RAG system components"""
        # Create Greek language prompt
        self.prompt = PromptTemplate(
            input_variables=["question", "context"],
            template="""
Î•Î¯ÏƒÏ„Îµ Î­Î½Î±Ï‚ ÎµÎ¾ÎµÎ¹Î´Î¹ÎºÎµÏ…Î¼Î­Î½Î¿Ï‚ Î²Î¿Î·Î¸ÏŒÏ‚ Î³Î¹Î± Ï„Î¿ ÎµÎ»Î»Î·Î½Î¹ÎºÏŒ Ï€Î¿Î´ÏŒÏƒÏ†Î±Î¹ÏÎ¿ ÎºÎ±Î¹ Ï„Î¿ Î½Ï„Î­ÏÎ¼Ï€Î¹ ÎŸÎ»Ï…Î¼Ï€Î¹Î±ÎºÏŒÏ‚-Î Î±Î½Î±Î¸Î·Î½Î±ÏŠÎºÏŒÏ‚.

Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®ÏƒÏ„Îµ Ï„Î¹Ï‚ Ï€Î±ÏÎ±ÎºÎ¬Ï„Ï‰ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ Î³Î¹Î± Î½Î± Î±Ï€Î±Î½Ï„Î®ÏƒÎµÏ„Îµ ÏƒÏ„Î·Î½ ÎµÏÏÏ„Î·ÏƒÎ· Ï„Î¿Ï… Ï‡ÏÎ®ÏƒÏ„Î·.
Î‘Î½ Î´ÎµÎ½ Î³Î½Ï‰ÏÎ¯Î¶ÎµÏ„Îµ Ï„Î·Î½ Î±Ï€Î¬Î½Ï„Î·ÏƒÎ·, Ï€ÎµÎ¯Ï„Îµ ÏŒÏ„Î¹ Î´ÎµÎ½ Î³Î½Ï‰ÏÎ¯Î¶ÎµÏ„Îµ.
Î‘Ï€Î±Î½Ï„Î®ÏƒÏ„Îµ ÏƒÏ„Î± ÎµÎ»Î»Î·Î½Î¹ÎºÎ¬ Î¼Îµ Ï†Î¹Î»Î¹ÎºÏŒ ÎºÎ±Î¹ ÎµÎ½Î·Î¼ÎµÏÏ‰Ï„Î¹ÎºÏŒ Ï„ÏÏŒÏ€Î¿.
ÎšÏÎ±Ï„Î®ÏƒÏ„Îµ Ï„Î¹Ï‚ Î±Ï€Î±Î½Ï„Î®ÏƒÎµÎ¹Ï‚ ÏƒÏ…Î½Î¿Ï€Ï„Î¹ÎºÎ­Ï‚ Î±Î»Î»Î¬ Ï€Î»Î®ÏÎµÎ¹Ï‚.

Î ÎµÏÎ¹ÎµÏ‡ÏŒÎ¼ÎµÎ½Î¿: {context}

Î•ÏÏÏ„Î·ÏƒÎ·: {question}
Î‘Ï€Î¬Î½Ï„Î·ÏƒÎ·:"""
        )
        
        # Define RAG functions
        def retrieve_greek_content(state: GreekDerbyState):
            retrieved_docs = self.vector_store.similarity_search(
                state["question"], 
                k=4
            )
            return {"context": retrieved_docs}

        def generate_greek_answer(state: GreekDerbyState):
            docs_content = "\n\n".join([doc.page_content for doc in state["context"]])
            messages = self.prompt.invoke({"question": state["question"], "context": docs_content})
            response = self.llm.invoke(messages)
            return {"answer": response.content}
        
        # Build RAG graph
        graph_builder = StateGraph(GreekDerbyState)
        graph_builder.add_sequence([retrieve_greek_content, generate_greek_answer])
        graph_builder.add_edge(START, "retrieve_greek_content")
        self.rag_graph = graph_builder.compile()
        
        print("âœ… RAG system initialized")
    
    def _init_memory(self):
        """Initialize conversation memory"""
        self.memory = ConversationBufferMemory(return_messages=True)
        self.conversation_history = []
        
        # Enhanced prompt for conversational RAG
        self.chat_prompt = ChatPromptTemplate.from_messages([
            ("system", """Î•Î¯ÏƒÏ„Îµ Î­Î½Î±Ï‚ ÎµÎ¾ÎµÎ¹Î´Î¹ÎºÎµÏ…Î¼Î­Î½Î¿Ï‚ Î²Î¿Î·Î¸ÏŒÏ‚ Î³Î¹Î± Ï„Î¿ ÎµÎ»Î»Î·Î½Î¹ÎºÏŒ Ï€Î¿Î´ÏŒÏƒÏ†Î±Î¹ÏÎ¿ ÎºÎ±Î¹ Ï„Î¿ Î½Ï„Î­ÏÎ¼Ï€Î¹ ÎŸÎ»Ï…Î¼Ï€Î¹Î±ÎºÏŒÏ‚-Î Î±Î½Î±Î¸Î·Î½Î±ÏŠÎºÏŒÏ‚.

Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®ÏƒÏ„Îµ Ï„Î¹Ï‚ Ï€Î±ÏÎ±ÎºÎ¬Ï„Ï‰ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ Î³Î¹Î± Î½Î± Î±Ï€Î±Î½Ï„Î®ÏƒÎµÏ„Îµ ÏƒÏ„Î·Î½ ÎµÏÏÏ„Î·ÏƒÎ· Ï„Î¿Ï… Ï‡ÏÎ®ÏƒÏ„Î·.
Î‘Î½ Î´ÎµÎ½ Î³Î½Ï‰ÏÎ¯Î¶ÎµÏ„Îµ Ï„Î·Î½ Î±Ï€Î¬Î½Ï„Î·ÏƒÎ·, Ï€ÎµÎ¯Ï„Îµ ÏŒÏ„Î¹ Î´ÎµÎ½ Î³Î½Ï‰ÏÎ¯Î¶ÎµÏ„Îµ.
Î‘Ï€Î±Î½Ï„Î®ÏƒÏ„Îµ ÏƒÏ„Î± ÎµÎ»Î»Î·Î½Î¹ÎºÎ¬ Î¼Îµ Ï†Î¹Î»Î¹ÎºÏŒ ÎºÎ±Î¹ ÎµÎ½Î·Î¼ÎµÏÏ‰Ï„Î¹ÎºÏŒ Ï„ÏÏŒÏ€Î¿.
ÎšÏÎ±Ï„Î®ÏƒÏ„Îµ Ï„Î¹Ï‚ Î±Ï€Î±Î½Ï„Î®ÏƒÎµÎ¹Ï‚ ÏƒÏ…Î½Î¿Ï€Ï„Î¹ÎºÎ­Ï‚ Î±Î»Î»Î¬ Ï€Î»Î®ÏÎµÎ¹Ï‚.

Î ÎµÏÎ¹ÎµÏ‡ÏŒÎ¼ÎµÎ½Î¿: {context}

Î ÏÎ¿Î·Î³Î¿ÏÎ¼ÎµÎ½Î· ÏƒÏ…Î½Î¿Î¼Î¹Î»Î¯Î±:
{chat_history}

Î•ÏÏÏ„Î·ÏƒÎ·: {question}
Î‘Ï€Î¬Î½Ï„Î·ÏƒÎ·:"""),
            MessagesPlaceholder(variable_name="chat_history"),
            ("human", "{question}")
        ])
        
        print("âœ… Memory system initialized")
    
    def _load_knowledge_base(self):
        """Load or create the knowledge base"""
        stats = self.index.describe_index_stats()
        
        if stats['total_vector_count'] == 0:
            print("ğŸ“š No knowledge base found. Creating sample content...")
            self._create_sample_knowledge_base()
        else:
            print(f"ğŸ“š Knowledge base loaded with {stats['total_vector_count']} vectors")
    
    def _create_sample_knowledge_base(self):
        """Create sample knowledge base with Greek derby content"""
        sample_content = """
ÎŸÎ»Ï…Î¼Ï€Î¹Î±ÎºÏŒÏ‚ vs Î Î±Î½Î±Î¸Î·Î½Î±ÏŠÎºÏŒÏ‚ - Î¤Î¿ ÎœÎµÎ³Î¬Î»Î¿ ÎÏ„Î­ÏÎ¼Ï€Î¹ Ï„Î·Ï‚ Î•Î»Î»Î¬Î´Î±Ï‚

Î¤Î¿ Î½Ï„Î­ÏÎ¼Ï€Î¹ Î¼ÎµÏ„Î±Î¾Ï ÎŸÎ»Ï…Î¼Ï€Î¹Î±ÎºÎ¿Ï ÎºÎ±Î¹ Î Î±Î½Î±Î¸Î·Î½Î±ÏŠÎºÎ¿Ï ÎµÎ¯Î½Î±Î¹ Ï„Î¿ Ï€Î¹Î¿ ÏƒÎ·Î¼Î±Î½Ï„Î¹ÎºÏŒ Ï€Î¿Î´Î¿ÏƒÏ†Î±Î¹ÏÎ¹ÎºÏŒ Î³ÎµÎ³Î¿Î½ÏŒÏ‚ ÏƒÏ„Î·Î½ Î•Î»Î»Î¬Î´Î±. 
Î‘Ï…Ï„ÏŒ Ï„Î¿ Î¼Î±Ï„Ï‚, Î³Î½Ï‰ÏƒÏ„ÏŒ Ï‰Ï‚ "Î¤Î¿ ÎœÎµÎ³Î¬Î»Î¿ ÎÏ„Î­ÏÎ¼Ï€Î¹", ÏƒÏ…Î³ÎºÎµÎ½Ï„ÏÏÎ½ÎµÎ¹ ÎµÎºÎ±Ï„Î¿Î¼Î¼ÏÏÎ¹Î± Î¸ÎµÎ±Ï„Î­Ï‚ ÎºÎ±Î¹ Ï†Î¹Î»Î¬Î¸Î»Î¿Ï…Ï‚.

Î™ÏƒÏ„Î¿ÏÎ¯Î± Ï„Î¿Ï… ÎÏ„Î­ÏÎ¼Ï€Î¹:
Î¤Î¿ Ï€ÏÏÏ„Î¿ ÎµÏ€Î¯ÏƒÎ·Î¼Î¿ Î¼Î±Ï„Ï‚ Î¼ÎµÏ„Î±Î¾Ï Ï„Ï‰Î½ Î´ÏÎ¿ Î¿Î¼Î¬Î´Ï‰Î½ Î­Î³Î¹Î½Îµ Ï„Î¿ 1925. Î‘Ï€ÏŒ Ï„ÏŒÏ„Îµ, Î­Ï‡Î¿Ï…Î½ Î±Î³Ï‰Î½Î¹ÏƒÏ„ÎµÎ¯ 
ÎµÎºÎ±Ï„Î¿Î½Ï„Î¬Î´ÎµÏ‚ Ï†Î¿ÏÎ­Ï‚, Î¼Îµ ÎºÎ¬Î¸Îµ Î¼Î±Ï„Ï‚ Î½Î± ÎµÎ¯Î½Î±Î¹ Î³ÎµÎ¼Î¬Ï„Î¿ Ï€Î¬Î¸Î¿Ï‚ ÎºÎ±Î¹ ÏƒÏ…Î½Î±Î¯ÏƒÎ¸Î·Î¼Î±.

Î£Î·Î¼Î±Î½Ï„Î¹ÎºÎ­Ï‚ Î£Ï„Î¹Î³Î¼Î­Ï‚:
- Î¤Î¿ 2004, Î¿ ÎŸÎ»Ï…Î¼Ï€Î¹Î±ÎºÏŒÏ‚ ÎºÎ­ÏÎ´Î¹ÏƒÎµ 3-1 ÏƒÏ„Î¿ ÎŸÎ‘ÎšÎ‘
- Î¤Î¿ 2007, Î¿ Î Î±Î½Î±Î¸Î·Î½Î±ÏŠÎºÏŒÏ‚ ÎµÏ€Î¹ÎºÏÎ¬Ï„Î·ÏƒÎµ 2-1 ÏƒÏ„Î¿ ÎšÎ±ÏÎ±ÏŠÏƒÎºÎ¬ÎºÎ·
- Î¤Î¿ 2010, Î¹ÏƒÏŒÏ€Î±Î»Î¿Ï‚ 1-1 Î¼Îµ Î±Î¾Î­Ï‡Î±ÏƒÏ„Î± Î³ÎºÎ¿Î»

ÎšÎ¿ÏÏ…Ï†Î±Î¯Î¿Î¹ Î Î±Î¯ÎºÏ„ÎµÏ‚:
- Î“Î¹ÏÏÎ³Î¿Ï‚ ÎšÎ±ÏÎ±Î³ÎºÎ¿ÏÎ½Î·Ï‚ (Î Î±Î½Î±Î¸Î·Î½Î±ÏŠÎºÏŒÏ‚)
- Î“Î¹ÏÏÎ³Î¿Ï‚ Î£ÎµÏŠÏ„Î±ÏÎ¯Î´Î·Ï‚ (ÎŸÎ»Ï…Î¼Ï€Î¹Î±ÎºÏŒÏ‚)
- Î‘Î½Ï„ÏÎ½Î·Ï‚ ÎÎ¹ÎºÎ¿Ï€Î¿Î»Î¯Î´Î·Ï‚ (ÎŸÎ»Ï…Î¼Ï€Î¹Î±ÎºÏŒÏ‚)
- Î‘Î½Ï„ÏÎ½Î·Ï‚ Î‘Î½Ï„Ï‰Î½Î¹Î¬Î´Î·Ï‚ (Î Î±Î½Î±Î¸Î·Î½Î±ÏŠÎºÏŒÏ‚)

Î£Î·Î¼Î±ÏƒÎ¯Î± Î³Î¹Î± Ï„Î¿Ï…Ï‚ Î¦Î¹Î»Î¬Î¸Î»Î¿Ï…Ï‚:
Î¤Î¿ Î½Ï„Î­ÏÎ¼Ï€Î¹ Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ Î±Ï€Î»Î¬ Î­Î½Î± Ï€Î¿Î´Î¿ÏƒÏ†Î±Î¹ÏÎ¹ÎºÏŒ Î¼Î±Ï„Ï‚, Î±Î»Î»Î¬ Î¼Î¹Î± ÏƒÏÎ³ÎºÏÎ¿Ï…ÏƒÎ· Ï„Î±Ï…Ï„Î¿Ï„Î®Ï„Ï‰Î½, 
Î¹ÏƒÏ„Î¿ÏÎ¹ÏÎ½ ÎºÎ±Î¹ Ï€Î±Î¸ÏÎ½. ÎšÎ¬Î¸Îµ Ï†Î¯Î»Î±Î¸Î»Î¿Ï‚ Ï€ÎµÏÎ¹Î¼Î­Î½ÎµÎ¹ Î¼Îµ Î±Î³Ï‰Î½Î¯Î± Î±Ï…Ï„ÏŒ Ï„Î¿ Î¼Î±Ï„Ï‚ ÏŒÎ»Î¿ Ï„Î¿ Ï‡ÏÏŒÎ½Î¿.

Î“Î®Ï€ÎµÎ´Î±:
- ÎŸÎ»Ï…Î¼Ï€Î¹Î±ÎºÏŒÏ‚: Î“ÎµÏÏÎ³Î¹Î¿Ï‚ ÎšÎ±ÏÎ±ÏŠÏƒÎºÎ¬ÎºÎ·Ï‚ (Î ÎµÎ¹ÏÎ±Î¹Î¬Ï‚)
- Î Î±Î½Î±Î¸Î·Î½Î±ÏŠÎºÏŒÏ‚: Î‘Ï€ÏŒÏƒÏ„Î¿Î»Î¿Ï‚ ÎÎ¹ÎºÎ¿Î»Î±ÎÎ´Î·Ï‚ (Î‘Î¸Î®Î½Î±)

Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬:
ÎŸ ÎŸÎ»Ï…Î¼Ï€Î¹Î±ÎºÏŒÏ‚ Î­Ï‡ÎµÎ¹ ÎºÎµÏÎ´Î¯ÏƒÎµÎ¹ Ï€ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎµÏ‚ Ï†Î¿ÏÎ­Ï‚ Ï„Î¿ Î½Ï„Î­ÏÎ¼Ï€Î¹ ÏƒÏ„Î·Î½ Î¹ÏƒÏ„Î¿ÏÎ¯Î±.
ÎŸÎ¹ Î±Î³ÏÎ½ÎµÏ‚ ÎµÎ¯Î½Î±Î¹ Î³ÎµÎ¼Î¬Ï„Î¿Î¹ Î­Î½Ï„Î±ÏƒÎ· ÎºÎ±Î¹ ÏƒÏ…Ï‡Î½Î¬ ÎºÏÎ¯Î½Î¿Ï…Î½ Ï„Î¯Ï„Î»Î¿Ï…Ï‚.
        """
        
        # Create document
        sample_doc = Document(
            page_content=sample_content,
            metadata={"source": "sample_content", "type": "greek_derby_info"}
        )
        
        # Split and store
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=100,
            separators=["\n\n", "\n", ". ", "! ", "? ", " ", ""]
        )
        
        splits = text_splitter.split_documents([sample_doc])
        self.vector_store.add_documents(splits)
        
        print(f"âœ… Sample knowledge base created with {len(splits)} chunks")
    
    def chat(self, user_input: str) -> str:
        """Process user input and return chatbot response"""
        try:
            # Get relevant context using RAG
            rag_response = self.rag_graph.invoke({"question": user_input})
            context = rag_response.get("context", [])
            
            # Format context for the prompt
            context_text = "\n\n".join([doc.page_content for doc in context])
            
            # Get conversation history
            chat_history = self.memory.chat_memory.messages
            
            # Create the prompt
            messages = self.chat_prompt.format_messages(
                context=context_text,
                chat_history=chat_history,
                question=user_input
            )
            
            # Get response from LLM
            response = self.llm.invoke(messages)
            
            # Store in memory
            self.memory.chat_memory.add_user_message(user_input)
            self.memory.chat_memory.add_ai_message(response.content)
            
            # Store in conversation history
            self.conversation_history.append({
                "timestamp": datetime.now().isoformat(),
                "user": user_input,
                "bot": response.content,
                "context_sources": [doc.metadata.get("source", "unknown") for doc in context]
            })
            
            return response.content
            
        except Exception as e:
            error_msg = f"Î£Ï†Î¬Î»Î¼Î±: {str(e)}"
            self.memory.chat_memory.add_user_message(user_input)
            self.memory.chat_memory.add_ai_message(error_msg)
            return error_msg
    
    def get_conversation_history(self) -> List[Dict[str, Any]]:
        """Get the full conversation history"""
        return self.conversation_history
    
    def clear_memory(self):
        """Clear conversation memory"""
        self.memory.clear()
        self.conversation_history = []
        print("Î— Î¼Î½Î®Î¼Î· Ï„Î·Ï‚ ÏƒÏ…Î½Î¿Î¼Î¹Î»Î¯Î±Ï‚ Î´Î¹Î±Î³ÏÎ¬Ï†Î·ÎºÎµ.")
    
    def get_memory_summary(self) -> str:
        """Get a summary of the conversation"""
        if not self.conversation_history:
            return "Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Î¹ÏƒÏ„Î¿ÏÎ¹ÎºÏŒ ÏƒÏ…Î½Î¿Î¼Î¹Î»Î¯Î±Ï‚."
        
        summary = f"Î£Ï…Î½Î¿Î¼Î¹Î»Î¯Î± Î¼Îµ {len(self.conversation_history)} ÎµÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚:\n"
        for i, conv in enumerate(self.conversation_history, 1):
            summary += f"{i}. Î•ÏÏÏ„Î·ÏƒÎ·: {conv['user'][:50]}...\n"
            summary += f"   Î‘Ï€Î¬Î½Ï„Î·ÏƒÎ·: {conv['bot'][:50]}...\n"
        
        return summary
    
    def export_conversation(self, filename: str = None):
        """Export conversation to JSON file"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"greek_derby_chat_{timestamp}.json"
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.conversation_history, f, ensure_ascii=False, indent=2)
        print(f"Î£Ï…Î½Î¿Î¼Î¹Î»Î¯Î± ÎµÎ¾Î®Ï‡Î¸Î· ÏƒÏ„Î¿ Î±ÏÏ‡ÎµÎ¯Î¿: {filename}")
    
    def get_stats(self) -> str:
        """Get conversation statistics"""
        if not self.conversation_history:
            return "Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ ÏƒÏ…Î½Î¿Î¼Î¹Î»Î¯Î± Î±ÎºÏŒÎ¼Î±."
        
        total_questions = len(self.conversation_history)
        total_chars = sum(len(conv['user']) + len(conv['bot']) for conv in self.conversation_history)
        avg_question_length = sum(len(conv['user']) for conv in self.conversation_history) / total_questions
        avg_answer_length = sum(len(conv['bot']) for conv in self.conversation_history) / total_questions
        
        return f"""
ğŸ“Š Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬ Î£Ï…Î½Î¿Î¼Î¹Î»Î¯Î±Ï‚:
- Î£Ï…Î½Î¿Î»Î¹ÎºÎ­Ï‚ Î•ÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚: {total_questions}
- Î£Ï…Î½Î¿Î»Î¹ÎºÎ¿Î¯ Î§Î±ÏÎ±ÎºÏ„Î®ÏÎµÏ‚: {total_chars:,}
- ÎœÎ­ÏƒÎ¿Ï‚ ÎŒÏÎ¿Ï‚ ÎœÎ®ÎºÎ¿Ï…Ï‚ Î•ÏÏÏ„Î·ÏƒÎ·Ï‚: {avg_question_length:.1f} Ï‡Î±ÏÎ±ÎºÏ„Î®ÏÎµÏ‚
- ÎœÎ­ÏƒÎ¿Ï‚ ÎŒÏÎ¿Ï‚ ÎœÎ®ÎºÎ¿Ï…Ï‚ Î‘Ï€Î¬Î½Ï„Î·ÏƒÎ·Ï‚: {avg_answer_length:.1f} Ï‡Î±ÏÎ±ÎºÏ„Î®ÏÎµÏ‚
"""

def print_welcome():
    """Print welcome message"""
    print("=" * 70)
    print("ğŸ‡¬ğŸ‡· GREEK DERBY RAG CHATBOT ğŸ‡¬ğŸ‡·")
    print("=" * 70)
    print("ÎšÎ±Î»ÏÏ‚ Î®ÏÎ¸Î±Ï„Îµ ÏƒÏ„Î¿ chatbot Î³Î¹Î± Ï„Î¿ Î½Ï„Î­ÏÎ¼Ï€Î¹ ÎŸÎ»Ï…Î¼Ï€Î¹Î±ÎºÏŒÏ‚-Î Î±Î½Î±Î¸Î·Î½Î±ÏŠÎºÏŒÏ‚!")
    print("ÎœÏ€Î¿ÏÎµÎ¯Ï„Îµ Î½Î± ÏÏ‰Ï„Î®ÏƒÎµÏ„Îµ Î¿Ï„Î¹Î´Î®Ï€Î¿Ï„Îµ ÏƒÏ‡ÎµÏ„Î¹ÎºÎ¬ Î¼Îµ Ï„Î¿ Î¼ÎµÎ³Î¬Î»Î¿ Î½Ï„Î­ÏÎ¼Ï€Î¹.")
    print("=" * 70)
    print("Î•Î½Ï„Î¿Î»Î­Ï‚:")
    print("  - Î¡Ï‰Ï„Î®ÏƒÏ„Îµ Î¿Ï„Î¹Î´Î®Ï€Î¿Ï„Îµ Î³Î¹Î± Ï„Î¿ Î½Ï„Î­ÏÎ¼Ï€Î¹")
    print("  - 'Î¹ÏƒÏ„Î¿ÏÎ¹ÎºÏŒ' - Î”ÎµÎ¯Ï„Îµ Ï„Î¿ Î¹ÏƒÏ„Î¿ÏÎ¹ÎºÏŒ ÏƒÏ…Î½Î¿Î¼Î¹Î»Î¯Î±Ï‚")
    print("  - 'Î´Î¹Î±Î³ÏÎ±Ï†Î®' - Î”Î¹Î±Î³ÏÎ¬ÏˆÏ„Îµ Ï„Î· Î¼Î½Î®Î¼Î·")
    print("  - 'ÏƒÏ„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬' - Î”ÎµÎ¯Ï„Îµ ÏƒÏ„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬")
    print("  - 'ÎµÎ¾Î±Î³Ï‰Î³Î®' - Î•Î¾Î¬Î³ÎµÏ„Îµ Ï„Î· ÏƒÏ…Î½Î¿Î¼Î¹Î»Î¯Î±")
    print("  - 'Î²Î¿Î®Î¸ÎµÎ¹Î±' - Î”ÎµÎ¯Ï„Îµ Î±Ï…Ï„Î­Ï‚ Ï„Î¹Ï‚ ÎµÎ½Ï„Î¿Î»Î­Ï‚")
    print("  - 'Î­Î¾Î¿Î´Î¿Ï‚' - Î¤ÎµÏÎ¼Î±Ï„Î¯ÏƒÏ„Îµ Ï„Î¿ Ï€ÏÏŒÎ³ÏÎ±Î¼Î¼Î±")
    print("=" * 70)

def main():
    """Main function to run the chatbot"""
    try:
        # Initialize chatbot
        chatbot = GreekDerbyChatbot()
        
        # Print welcome message
        print_welcome()
        
        # Main chat loop
        while True:
            try:
                # Get user input
                user_input = input("\nğŸ‘¤ Î•ÏƒÎµÎ¯Ï‚: ").strip()
                
                # Handle special commands
                if user_input.lower() in ['Î­Î¾Î¿Î´Î¿Ï‚', 'exit', 'quit', 'q']:
                    print("\nğŸ‘‹ Î‘Î½Ï„Î¯Î¿! Î•Ï…Ï‡Î±ÏÎ¹ÏƒÏ„Î¿ÏÎ¼Îµ Ï€Î¿Ï… ÏƒÏ…Î½Î¿Î¼Î»Î®ÏƒÎ±Ï„Îµ Î³Î¹Î± Ï„Î¿ Î½Ï„Î­ÏÎ¼Ï€Î¹!")
                    break
                elif user_input.lower() == 'Î¹ÏƒÏ„Î¿ÏÎ¹ÎºÏŒ':
                    print("\nğŸ“š Î™ÏƒÏ„Î¿ÏÎ¹ÎºÏŒ Î£Ï…Î½Î¿Î¼Î¹Î»Î¯Î±Ï‚:")
                    print(chatbot.get_memory_summary())
                    continue
                elif user_input.lower() == 'Î´Î¹Î±Î³ÏÎ±Ï†Î®':
                    chatbot.clear_memory()
                    continue
                elif user_input.lower() == 'ÏƒÏ„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬':
                    print(chatbot.get_stats())
                    continue
                elif user_input.lower() == 'ÎµÎ¾Î±Î³Ï‰Î³Î®':
                    chatbot.export_conversation()
                    continue
                elif user_input.lower() == 'Î²Î¿Î®Î¸ÎµÎ¹Î±':
                    print_welcome()
                    continue
                elif not user_input:
                    print("Î Î±ÏÎ±ÎºÎ±Î»Ï ÎµÎ¹ÏƒÎ¬Î³ÎµÏ„Îµ Î¼Î¹Î± ÎµÏÏÏ„Î·ÏƒÎ· Î® ÎµÎ½Ï„Î¿Î»Î®.")
                    continue
                
                # Get chatbot response
                print("\nğŸ¤– Bot: ", end="")
                response = chatbot.chat(user_input)
                print(response)
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ Î‘Î½Ï„Î¯Î¿! Î•Ï…Ï‡Î±ÏÎ¹ÏƒÏ„Î¿ÏÎ¼Îµ Ï€Î¿Ï… ÏƒÏ…Î½Î¿Î¼Î»Î®ÏƒÎ±Ï„Îµ Î³Î¹Î± Ï„Î¿ Î½Ï„Î­ÏÎ¼Ï€Î¹!")
                break
            except Exception as e:
                print(f"\nâŒ Î£Ï†Î¬Î»Î¼Î±: {e}")
                print("Î Î±ÏÎ±ÎºÎ±Î»Ï Î´Î¿ÎºÎ¹Î¼Î¬ÏƒÏ„Îµ Î¾Î±Î½Î¬ Î® Ï€Î»Î·ÎºÏ„ÏÎ¿Î»Î¿Î³Î®ÏƒÏ„Îµ 'Î­Î¾Î¿Î´Î¿Ï‚' Î³Î¹Î± Î½Î± Ï„ÎµÏÎ¼Î±Ï„Î¯ÏƒÎµÏ„Îµ.")
    
    except Exception as e:
        print(f"âŒ ÎšÏÎ¯ÏƒÎ¹Î¼Î¿ ÏƒÏ†Î¬Î»Î¼Î± ÎºÎ±Ï„Î¬ Ï„Î·Î½ Î±ÏÏ‡Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·: {e}")
        print("Î Î±ÏÎ±ÎºÎ±Î»Ï ÎµÎ»Î­Î³Î¾Ï„Îµ Ï„Î¹Ï‚ Î¼ÎµÏ„Î±Î²Î»Î·Ï„Î­Ï‚ Ï€ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½Ï„Î¿Ï‚ ÎºÎ±Î¹ Ï„Î¹Ï‚ ÏƒÏ…Î½Î´Î­ÏƒÎµÎ¹Ï‚.")
        sys.exit(1)

if __name__ == "__main__":
    main()
