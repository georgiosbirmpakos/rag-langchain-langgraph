{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Greek Derby RAG System - Olympiakos vs Panathinaikos\n",
        "## RAG System for Greek Football Derby Analysis using Gazzetta.gr\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading Environment Variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key loaded: True\n",
            "Pinecone API Key loaded: True\n",
            "Pinecone Index Name: rag\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Verify API keys are loaded\n",
        "print(f\"OpenAI API Key loaded: {bool(os.getenv('OPENAI_API_KEY'))}\")\n",
        "print(f\"Pinecone API Key loaded: {bool(os.getenv('PINECONE_API_KEY'))}\")\n",
        "print(f\"Pinecone Index Name: {os.getenv('PINECONE_INDEX_NAME')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Selecting Chat Model for Greek Language\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Greek Language Test: Γεια σας! Ναι, μπορώ να μιλήσω ελληνικά. Πώς μπορώ να σας βοηθήσω σήμερα;\n"
          ]
        }
      ],
      "source": [
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "# Initialize GPT-4o-mini with Greek language support\n",
        "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
        "\n",
        "# Test Greek language capability\n",
        "test_response = llm.invoke(\"Γεια σας! Μπορείτε να μιλήσετε ελληνικά;\")\n",
        "print(f\"Greek Language Test: {test_response.content}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Selecting Embeddings Model for Greek Text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Greek text embedding dimension: 1024\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# OpenAI Embedding Models optimized for multilingual content including Greek:\n",
        "# - text-embedding-3-small: 1536 dimensions (good for Greek)\n",
        "# - text-embedding-3-large: 3072 dimensions (best for Greek)\n",
        "# - text-embedding-3-small with dimensions=1024: 1024 dimensions (balanced)\n",
        "\n",
        "embeddings = OpenAIEmbeddings(\n",
        "    model=\"text-embedding-3-small\",\n",
        "    dimensions=1024  # Good balance for Greek text\n",
        ")\n",
        "\n",
        "# Test Greek text embedding\n",
        "test_text = \"Ολυμπιακός vs Παναθηναϊκός - το μεγάλο ντέρμπι της Ελλάδας\"\n",
        "test_embedding = embeddings.embed_query(test_text)\n",
        "print(f\"Greek text embedding dimension: {len(test_embedding)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setting up Vector Store for Greek Content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\PX\\anaconda3\\envs\\music-chatbot\\lib\\site-packages\\langchain_pinecone\\__init__.py:3: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
            "\n",
            "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
            "with: `from pydantic import BaseModel`\n",
            "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
            "\n",
            "  from langchain_pinecone.vectorstores import Pinecone, PineconeVectorStore\n",
            "Index host ignored when initializing with index object.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector store initialized for Greek content\n",
            "Index stats: {'dimension': 1024,\n",
            " 'index_fullness': 0.0,\n",
            " 'metric': 'cosine',\n",
            " 'namespaces': {'': {'vector_count': 160}},\n",
            " 'total_vector_count': 160,\n",
            " 'vector_type': 'dense'}\n"
          ]
        }
      ],
      "source": [
        "from langchain_pinecone import PineconeVectorStore\n",
        "from pinecone import Pinecone\n",
        "\n",
        "# Initialize Pinecone\n",
        "pc = Pinecone(api_key=os.getenv('PINECONE_API_KEY'))\n",
        "index = pc.Index(\"greekderby\")\n",
        "\n",
        "# Create vector store for Greek content\n",
        "vector_store = PineconeVectorStore(embedding=embeddings, index=index)\n",
        "\n",
        "print(f\"Vector store initialized for Greek content\")\n",
        "print(f\"Index stats: {index.describe_index_stats()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading Greek Football Content from Gazzetta.gr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading Greek football content from Gazzetta.gr...\n",
            "Loading: https://www.gazzetta.gr/football/superleague/olympiakos\n",
            "  No content found with selectors, trying without filtering...\n",
            "  Found 1 valid documents from https://www.gazzetta.gr/football/superleague/olympiakos\n",
            "Loading: https://www.gazzetta.gr/football/superleague/panathinaikos\n",
            "  No content found with selectors, trying without filtering...\n",
            "  Found 1 valid documents from https://www.gazzetta.gr/football/superleague/panathinaikos\n",
            "Loading: https://www.gazzetta.gr/football/superleague\n",
            "  No content found with selectors, trying without filtering...\n",
            "  Found 1 valid documents from https://www.gazzetta.gr/football/superleague\n",
            "Loaded 3 documents from Gazzetta.gr\n"
          ]
        }
      ],
      "source": [
        "import bs4\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from urllib.parse import urljoin, urlparse\n",
        "import time\n",
        "import requests\n",
        "\n",
        "# Set user agent to avoid blocking\n",
        "os.environ['USER_AGENT'] = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "\n",
        "# URLs to scrape from Gazzetta.gr related to Olympiakos and Panathinaikos\n",
        "greek_derby_urls = [\n",
        "    \"https://www.gazzetta.gr/football/superleague/olympiakos\",\n",
        "    \"https://www.gazzetta.gr/football/superleague/panathinaikos\",\n",
        "    \"https://www.gazzetta.gr/football/superleague\"\n",
        "]\n",
        "\n",
        "print(\"Loading Greek football content from Gazzetta.gr...\")\n",
        "\n",
        "# Load content from multiple URLs with better selectors\n",
        "all_docs = []\n",
        "for url in greek_derby_urls:\n",
        "    try:\n",
        "        print(f\"Loading: {url}\")\n",
        "        \n",
        "        # First try with broader selectors to get more content\n",
        "        loader = WebBaseLoader(\n",
        "            web_paths=(url,),\n",
        "            bs_kwargs=dict(\n",
        "                parse_only=bs4.SoupStrainer(\n",
        "                    class_=(\"article-content\", \"article-title\", \"article-body\", \"content\", \"post-content\", \n",
        "                           \"entry-content\", \"post-body\", \"article-text\", \"main-content\", \"story-content\",\n",
        "                           \"article\", \"post\", \"content-area\", \"main\", \"body\")\n",
        "                )\n",
        "            ),\n",
        "        )\n",
        "        docs = loader.load()\n",
        "        \n",
        "        # If no content found, try without any class filtering\n",
        "        if not docs or all(len(doc.page_content.strip()) < 100 for doc in docs):\n",
        "            print(f\"  No content found with selectors, trying without filtering...\")\n",
        "            loader_fallback = WebBaseLoader(web_paths=(url,))\n",
        "            docs = loader_fallback.load()\n",
        "        \n",
        "        # Filter out very short documents\n",
        "        valid_docs = [doc for doc in docs if len(doc.page_content.strip()) > 50]\n",
        "        all_docs.extend(valid_docs)\n",
        "        \n",
        "        print(f\"  Found {len(valid_docs)} valid documents from {url}\")\n",
        "        time.sleep(1)  # Be respectful to the server\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {url}: {e}\")\n",
        "        continue\n",
        "\n",
        "print(f\"Loaded {len(all_docs)} documents from Gazzetta.gr\")\n",
        "\n",
        "# If still no content, try a different approach with requests\n",
        "if len(all_docs) == 0 or all(len(doc.page_content.strip()) < 100 for doc in all_docs):\n",
        "    print(\"\\nTrying alternative approach with requests...\")\n",
        "    try:\n",
        "        response = requests.get(\"https://www.gazzetta.gr/football/superleague\", \n",
        "                              headers={'User-Agent': os.environ['USER_AGENT']})\n",
        "        if response.status_code == 200:\n",
        "            from langchain_core.documents import Document\n",
        "            # Create a document from the raw HTML content\n",
        "            fallback_doc = Document(\n",
        "                page_content=response.text,\n",
        "                metadata={\"source\": \"https://www.gazzetta.gr/football/superleague\", \"method\": \"requests\"}\n",
        "            )\n",
        "            all_docs.append(fallback_doc)\n",
        "            print(\"Added fallback document from requests\")\n",
        "    except Exception as e:\n",
        "        print(f\"Fallback approach also failed: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Splitting Greek Documents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Debugging loaded documents:\n",
            "\n",
            "Document 1:\n",
            "  Length: 19839 characters\n",
            "  Content preview: Ποδόσφαιρο Ολυμπιακός Νέα - Ειδήσεις - Αγώνες | gazzetta.gr\n",
            "   Παράκαμψη προς το κυρίως περιεχόμενο       Slogun:Αφού η Κηφισιά δήλωσε έδρα το Αγρίνιο, ο Παναιτωλικός με τέτοια αποτελέσματα ψάχνει γήπ...\n",
            "  Metadata: {'source': 'https://www.gazzetta.gr/football/superleague/olympiakos', 'title': 'Ποδόσφαιρο Ολυμπιακός Νέα - Ειδήσεις - Αγώνες | gazzetta.gr', 'description': 'Ανακαλύψτε τα τελευταία νέα Ποδόσφαιρο Ολυμπιακός στο gazzetta.gr. Ενημερωθείτε πρώτοι για όλες τις εξελίξεις Ποδόσφαιρο Ολυμπιακός και μείνετε συντονισμένοι!', 'language': 'el'}\n",
            "\n",
            "Document 2:\n",
            "  Length: 18613 characters\n",
            "  Content preview: Ποδόσφαιρο Παναθηναϊκός Νέα - Ειδήσεις - Αγώνες | gazzetta.gr\n",
            "   Παράκαμψη προς το κυρίως περιεχόμενο       Slogun:Αφού η Κηφισιά δήλωσε έδρα το Αγρίνιο, ο Παναιτωλικός με τέτοια αποτελέσματα ψάχνει γ...\n",
            "  Metadata: {'source': 'https://www.gazzetta.gr/football/superleague/panathinaikos', 'title': 'Ποδόσφαιρο Παναθηναϊκός Νέα - Ειδήσεις - Αγώνες | gazzetta.gr', 'description': 'Ανακαλύψτε τα τελευταία νέα Ποδόσφαιρο Παναθηναϊκός στο gazzetta.gr. Ενημερωθείτε πρώτοι για όλες τις εξελίξεις Ποδόσφαιρο Παναθηναϊκός και μείνετε συντονισμένοι!', 'language': 'el'}\n",
            "\n",
            "Document 3:\n",
            "  Length: 16414 characters\n",
            "  Content preview: Superleague Νέα & Ειδήσεις | gazzetta.gr\n",
            "   Παράκαμψη προς το κυρίως περιεχόμενο       Slogun:Αφού η Κηφισιά δήλωσε έδρα το Αγρίνιο, ο Παναιτωλικός με τέτοια αποτελέσματα ψάχνει γήπεδο στη Θεσσαλονίκη...\n",
            "  Metadata: {'source': 'https://www.gazzetta.gr/football/superleague', 'title': 'Superleague Νέα & Ειδήσεις | gazzetta.gr', 'description': 'Superleague: Τελευταία νέα, αποτελέσματα, πρόγραμμα και βαθμολογίες! Όλες οι τελευταίες ειδήσεις για το Super League στο Gazzetta.gr', 'language': 'el'}\n",
            "\n",
            "Created 161 text chunks from Greek content\n",
            "\n",
            "Sample chunk content:\n",
            "Length: 59 characters\n",
            "Content: Ποδόσφαιρο Ολυμπιακός Νέα - Ειδήσεις - Αγώνες | gazzetta.gr...\n"
          ]
        }
      ],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Debug: Check what's actually in the loaded documents\n",
        "print(\"Debugging loaded documents:\")\n",
        "for i, doc in enumerate(all_docs):\n",
        "    print(f\"\\nDocument {i+1}:\")\n",
        "    print(f\"  Length: {len(doc.page_content)} characters\")\n",
        "    print(f\"  Content preview: {doc.page_content[:200]}...\")\n",
        "    print(f\"  Metadata: {doc.metadata}\")\n",
        "\n",
        "# Try with smaller chunk size to see if we can get any chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,  # Reduced from 1000\n",
        "    chunk_overlap=100,  # Reduced from 200\n",
        "    separators=[\"\\n\\n\", \"\\n\", \". \", \"! \", \"? \", \" \", \"\"]  # Greek-friendly separators\n",
        ")\n",
        "\n",
        "all_splits = text_splitter.split_documents(all_docs)\n",
        "print(f\"\\nCreated {len(all_splits)} text chunks from Greek content\")\n",
        "\n",
        "# If still 0 chunks, try even smaller\n",
        "if len(all_splits) == 0:\n",
        "    print(\"\\nTrying with even smaller chunks...\")\n",
        "    text_splitter_small = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=100,  # Very small chunks\n",
        "        chunk_overlap=20,\n",
        "        separators=[\"\\n\", \". \", \"! \", \"? \", \" \", \"\"]\n",
        "    )\n",
        "    all_splits = text_splitter_small.split_documents(all_docs)\n",
        "    print(f\"Created {len(all_splits)} text chunks with small size\")\n",
        "\n",
        "# Show sample chunks if any were created\n",
        "if all_splits:\n",
        "    print(f\"\\nSample chunk content:\")\n",
        "    print(f\"Length: {len(all_splits[0].page_content)} characters\")\n",
        "    print(f\"Content: {all_splits[0].page_content[:300]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Storing Greek Content in Vector Database\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Storing Greek football content in vector database...\n",
            "Vector database stats: {'dimension': 1024,\n",
            " 'index_fullness': 0.0,\n",
            " 'metric': 'cosine',\n",
            " 'namespaces': {'': {'vector_count': 193}},\n",
            " 'total_vector_count': 193,\n",
            " 'vector_type': 'dense'}\n",
            "Total vectors: 193\n"
          ]
        }
      ],
      "source": [
        "# Clear existing content and add new Greek content\n",
        "print(\"Storing Greek football content in vector database...\")\n",
        "\n",
        "# Add documents to vector store\n",
        "_ = vector_store.add_documents(documents=all_splits)\n",
        "\n",
        "# Check index stats\n",
        "stats = index.describe_index_stats()\n",
        "print(f\"Vector database stats: {stats}\")\n",
        "print(f\"Total vectors: {stats['total_vector_count']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating Greek Language RAG Prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Greek RAG prompt created successfully\n",
            "Prompt template: \n",
            "Είστε ένας βοηθός για ερωτήσεις σχετικά με το ελληνικό ποδόσφαιρο και το ντέρμπι Ολυμπιακός-Παναθην...\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Custom Greek language prompt for football derby questions\n",
        "greek_prompt_template = \"\"\"\n",
        "Είστε ένας βοηθός για ερωτήσεις σχετικά με το ελληνικό ποδόσφαιρο και το ντέρμπι Ολυμπιακός-Παναθηναϊκός.\n",
        "Χρησιμοποιήστε τα παρακάτω κομμάτια πληροφοριών για να απαντήσετε στην ερώτηση.\n",
        "Αν δεν γνωρίζετε την απάντηση, απλά πείτε ότι δεν γνωρίζετε.\n",
        "Χρησιμοποιήστε μέχρι τρεις προτάσεις και κρατήστε την απάντηση συνοπτική.\n",
        "Απαντήστε στα ελληνικά.\n",
        "\n",
        "Ερώτηση: {question}\n",
        "Περιεχόμενο: {context}\n",
        "Απάντηση:\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"question\", \"context\"],\n",
        "    template=greek_prompt_template\n",
        ")\n",
        "\n",
        "print(\"Greek RAG prompt created successfully\")\n",
        "print(f\"Prompt template: {prompt.template[:100]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setting up Greek RAG Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Greek RAG functions defined successfully\n"
          ]
        }
      ],
      "source": [
        "from typing_extensions import List, TypedDict\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "# Define state for Greek RAG application\n",
        "class GreekDerbyState(TypedDict):\n",
        "    question: str\n",
        "    context: List[Document]\n",
        "    answer: str\n",
        "\n",
        "# Define application steps for Greek content\n",
        "def retrieve_greek_content(state: GreekDerbyState):\n",
        "    \"\"\"Retrieve relevant Greek football content based on question\"\"\"\n",
        "    retrieved_docs = vector_store.similarity_search(\n",
        "        state[\"question\"], \n",
        "        k=4  # Get top 4 most relevant documents\n",
        "    )\n",
        "    return {\"context\": retrieved_docs}\n",
        "\n",
        "def generate_greek_answer(state: GreekDerbyState):\n",
        "    \"\"\"Generate answer in Greek based on retrieved context\"\"\"\n",
        "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
        "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
        "    response = llm.invoke(messages)\n",
        "    return {\"answer\": response.content}\n",
        "\n",
        "print(\"Greek RAG functions defined successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Building the Greek RAG LangGraph\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Greek Derby RAG graph compiled successfully\n",
            "Graph nodes: ['__start__', 'retrieve_greek_content', 'generate_greek_answer', '__end__']\n"
          ]
        }
      ],
      "source": [
        "from langgraph.graph import START, StateGraph\n",
        "\n",
        "# Build the Greek RAG graph\n",
        "graph_builder = StateGraph(GreekDerbyState)\n",
        "graph_builder.add_sequence([retrieve_greek_content, generate_greek_answer])\n",
        "graph_builder.add_edge(START, \"retrieve_greek_content\")\n",
        "\n",
        "# Compile the graph\n",
        "greek_derby_graph = graph_builder.compile()\n",
        "\n",
        "print(\"Greek Derby RAG graph compiled successfully\")\n",
        "print(f\"Graph nodes: {list(greek_derby_graph.get_graph().nodes.keys())}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing the Greek Derby RAG System\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing Greek Derby RAG System...\n",
            "==================================================\n",
            "\n",
            "Ερώτηση 1: Ποια είναι η ιστορία του ντέρμπι Ολυμπιακός-Παναθηναϊκός;\n",
            "------------------------------\n",
            "Απάντηση: Η ιστορία του ντέρμπι Ολυμπιακός-Παναθηναϊκός είναι γεμάτη εντάσεις και ανταγωνισμό, καθώς πρόκειται για μία από τις πιο ιστορικές αντιπαραθέσεις στο ελληνικό ποδόσφαιρο. Οι δύο ομάδες, γνωστές και ως \"αιώνιοι αντίπαλοι\", έχουν συναντηθεί πολλές φορές και οι αγώνες τους συχνά κρίνουν τίτλους και φιλοδοξίες. Το ντέρμπι συνήθως συνοδεύεται από πάθος και είναι γεμάτο ειδικές συνθήκες, όπως αλλαγές προπονητών και άλλες συγκυρίες που επηρεάζουν την ψυχολογία των ομάδων.\n",
            "\n",
            "\n",
            "Ερώτηση 2: Ποιος έχει κερδίσει περισσότερες φορές το ντέρμπι;\n",
            "------------------------------\n",
            "Απάντηση: Δεν γνωρίζω.\n",
            "\n",
            "\n",
            "Ερώτηση 3: Ποια είναι τα πιο αξέχαστα γκολ στο ντέρμπι;\n",
            "------------------------------\n",
            "Απάντηση: Δεν γνωρίζω συγκεκριμένα ποια είναι τα πιο αξέχαστα γκολ στο ντέρμπι Ολυμπιακού-Παναθηναϊκού.\n",
            "\n",
            "\n",
            "Ερώτηση 4: Ποιοι είναι οι κορυφαίοι παίκτες που έχουν αγωνιστεί στο ντέρμπι;\n",
            "------------------------------\n",
            "Απάντηση: Δεν γνωρίζω ποιους συγκεκριμένα κορυφαίους παίκτες έχουν αγωνιστεί στο ντέρμπι Ολυμπιακός-Παναθηναϊκός.\n",
            "\n",
            "\n",
            "Ερώτηση 5: Ποια είναι η σημασία του ντέρμπι για τους φιλάθλους;\n",
            "------------------------------\n",
            "Απάντηση: Το ντέρμπι Ολυμπιακού - Παναθηναϊκού είναι ιδιαίτερα σημαντικό για τους φιλάθλους καθώς συμβολίζει μια βαθιά ριζωμένη rivality και έντονα συναισθήματα. Για τους «μπαρουτοκαπνισμένους» φιλάθλους, η σημασία του αγώνα προέρχεται από την ιστορία και την παράδοση μεταξύ των δύο ομάδων. Κάθε ντέρμπι παίρνει διαφορετικές διαστάσεις με ειδικές συνθήκες, όπως η αλλαγή προπονητή στον αντίπαλο.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test questions about Olympiakos vs Panathinaikos derby\n",
        "test_questions = [\n",
        "    \"Ποια είναι η ιστορία του ντέρμπι Ολυμπιακός-Παναθηναϊκός;\",\n",
        "    \"Ποιος έχει κερδίσει περισσότερες φορές το ντέρμπι;\",\n",
        "    \"Ποια είναι τα πιο αξέχαστα γκολ στο ντέρμπι;\",\n",
        "    \"Ποιοι είναι οι κορυφαίοι παίκτες που έχουν αγωνιστεί στο ντέρμπι;\",\n",
        "    \"Ποια είναι η σημασία του ντέρμπι για τους φιλάθλους;\"\n",
        "]\n",
        "\n",
        "print(\"Testing Greek Derby RAG System...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "for i, question in enumerate(test_questions, 1):\n",
        "    print(f\"\\nΕρώτηση {i}: {question}\")\n",
        "    print(\"-\" * 30)\n",
        "    \n",
        "    try:\n",
        "        response = greek_derby_graph.invoke({\"question\": question})\n",
        "        print(f\"Απάντηση: {response['answer']}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Σφάλμα: {e}\")\n",
        "    \n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Interactive Greek Derby Chat\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ερώτηση: Που γίνεται το ντέρμπι Ολυμπιακός-Παναθηναϊκός;\n",
            "Αναζήτηση πληροφοριών...\n",
            "\n",
            "Απάντηση: Το ντέρμπι Ολυμπιακός-Παναθηναϊκός γίνεται συνήθως στο γήπεδο του Ολυμπιακού, το Γεώργιος Καραϊσκάκης, ή στο γήπεδο του Παναθηναϊκού, το Απόστολος Νικολαΐδης, ανάλογα με την έδρα της κάθε ομάδας.\n",
            "\n",
            "Πηγές:\n",
            "1. Ολυμπιακός: Ο δρόμος για το ντέρμπι είναι ένας και ειδικά οι «μπαρουτοκαπνισμένοι» τον ξέρουν καλά  ...\n",
            "2. Ολυμπιακός: Ο δρόμος για το ντέρμπι είναι ένας και ειδικά οι «μπαρουτοκαπνισμένοι» τον ξέρουν καλά  ...\n",
            "3. Ολυμπιακός: Ο δρόμος για το ντέρμπι είναι ένας και ειδικά οι «μπαρουτοκαπνισμένοι» τον ξέρουν καλά  ...\n",
            "4. Ολυμπιακός: Ο δρόμος για το ντέρμπι είναι ένας και ειδικά οι «μπαρουτοκαπνισμένοι» τον ξέρουν καλά  ...\n"
          ]
        }
      ],
      "source": [
        "def ask_greek_derby_question(question: str):\n",
        "    \"\"\"Interactive function to ask questions about the Greek derby\"\"\"\n",
        "    print(f\"Ερώτηση: {question}\")\n",
        "    print(\"Αναζήτηση πληροφοριών...\")\n",
        "    \n",
        "    try:\n",
        "        response = greek_derby_graph.invoke({\"question\": question})\n",
        "        print(f\"\\nΑπάντηση: {response['answer']}\")\n",
        "        \n",
        "        # Show sources\n",
        "        print(\"\\nΠηγές:\")\n",
        "        for i, doc in enumerate(response['context'], 1):\n",
        "            print(f\"{i}. {doc.page_content[:100]}...\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"Σφάλμα: {e}\")\n",
        "\n",
        "\n",
        "# Uncomment to test interactive mode\n",
        "ask_greek_derby_question(\"Που γίνεται το ντέρμπι Ολυμπιακός-Παναθηναϊκός;\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Performance Metrics and Monitoring\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Greek RAG benchmark...\n",
            "\n",
            "Benchmark Results:\n",
            "Total Questions: 3\n",
            "Successful Answers: 3\n",
            "Failed Answers: 0\n",
            "Average Response Time: 1.95 seconds\n",
            "Success Rate: 100.0%\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from typing import Dict, Any\n",
        "\n",
        "def benchmark_greek_rag(questions: list) -> Dict[str, Any]:\n",
        "    \"\"\"Benchmark the Greek RAG system performance\"\"\"\n",
        "    results = {\n",
        "        'total_questions': len(questions),\n",
        "        'successful_answers': 0,\n",
        "        'failed_answers': 0,\n",
        "        'average_response_time': 0,\n",
        "        'total_time': 0\n",
        "    }\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    for question in questions:\n",
        "        question_start = time.time()\n",
        "        try:\n",
        "            response = greek_derby_graph.invoke({\"question\": question})\n",
        "            if response['answer']:\n",
        "                results['successful_answers'] += 1\n",
        "            else:\n",
        "                results['failed_answers'] += 1\n",
        "        except Exception as e:\n",
        "            results['failed_answers'] += 1\n",
        "            print(f\"Error with question '{question}': {e}\")\n",
        "        \n",
        "        question_time = time.time() - question_start\n",
        "        results['total_time'] += question_time\n",
        "    \n",
        "    results['average_response_time'] = results['total_time'] / len(questions)\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Run benchmark\n",
        "benchmark_questions = [\n",
        "    \"Ποια είναι η ιστορία του ντέρμπι;\",\n",
        "    \"Ποιος έχει κερδίσει περισσότερες φορές;\",\n",
        "    \"Ποια είναι τα πιο αξέχαστα γκολ;\"\n",
        "]\n",
        "\n",
        "print(\"Running Greek RAG benchmark...\")\n",
        "benchmark_results = benchmark_greek_rag(benchmark_questions)\n",
        "\n",
        "print(\"\\nBenchmark Results:\")\n",
        "print(f\"Total Questions: {benchmark_results['total_questions']}\")\n",
        "print(f\"Successful Answers: {benchmark_results['successful_answers']}\")\n",
        "print(f\"Failed Answers: {benchmark_results['failed_answers']}\")\n",
        "print(f\"Average Response Time: {benchmark_results['average_response_time']:.2f} seconds\")\n",
        "print(f\"Success Rate: {(benchmark_results['successful_answers'] / benchmark_results['total_questions']) * 100:.1f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Interactive Greek Derby Chatbot with Memory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🤖 Greek Derby Chatbot initialized with memory!\n",
            "You can now have a conversation about Olympiakos vs Panathinaikos derby.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\PX\\AppData\\Local\\Temp\\ipykernel_10180\\3506290698.py:10: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  self.memory = ConversationBufferMemory(return_messages=True)\n"
          ]
        }
      ],
      "source": [
        "from typing import List, Dict, Any\n",
        "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "class GreekDerbyChatbot:\n",
        "    def __init__(self, rag_graph, llm):\n",
        "        self.rag_graph = rag_graph\n",
        "        self.llm = llm\n",
        "        self.memory = ConversationBufferMemory(return_messages=True)\n",
        "        self.conversation_history = []\n",
        "        \n",
        "        # Enhanced prompt for conversational RAG\n",
        "        self.chat_prompt = ChatPromptTemplate.from_messages([\n",
        "            (\"system\", \"\"\"Είστε ένας εξειδικευμένος βοηθός για το ελληνικό ποδόσφαιρο και το ντέρμπι Ολυμπιακός-Παναθηναϊκός.\n",
        "            \n",
        "Χρησιμοποιήστε τις παρακάτω πληροφορίες για να απαντήσετε στην ερώτηση του χρήστη.\n",
        "Αν δεν γνωρίζετε την απάντηση, πείτε ότι δεν γνωρίζετε.\n",
        "Απαντήστε στα ελληνικά με φιλικό και ενημερωτικό τρόπο.\n",
        "Κρατήστε τις απαντήσεις συνοπτικές αλλά πλήρεις.\n",
        "\n",
        "Περιεχόμενο: {context}\n",
        "\n",
        "Προηγούμενη συνομιλία:\n",
        "{chat_history}\n",
        "\n",
        "Ερώτηση: {question}\n",
        "Απάντηση:\"\"\"),\n",
        "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "            (\"human\", \"{question}\")\n",
        "        ])\n",
        "    \n",
        "    def chat(self, user_input: str) -> str:\n",
        "        \"\"\"Process user input and return chatbot response\"\"\"\n",
        "        try:\n",
        "            # Get relevant context using RAG\n",
        "            rag_response = self.rag_graph.invoke({\"question\": user_input})\n",
        "            context = rag_response.get(\"context\", [])\n",
        "            \n",
        "            # Format context for the prompt\n",
        "            context_text = \"\\n\\n\".join([doc.page_content for doc in context])\n",
        "            \n",
        "            # Get conversation history\n",
        "            chat_history = self.memory.chat_memory.messages\n",
        "            \n",
        "            # Create the prompt\n",
        "            messages = self.chat_prompt.format_messages(\n",
        "                context=context_text,\n",
        "                chat_history=chat_history,\n",
        "                question=user_input\n",
        "            )\n",
        "            \n",
        "            # Get response from LLM\n",
        "            response = self.llm.invoke(messages)\n",
        "            \n",
        "            # Store in memory\n",
        "            self.memory.chat_memory.add_user_message(user_input)\n",
        "            self.memory.chat_memory.add_ai_message(response.content)\n",
        "            \n",
        "            # Store in conversation history\n",
        "            self.conversation_history.append({\n",
        "                \"user\": user_input,\n",
        "                \"bot\": response.content,\n",
        "                \"context_sources\": [doc.metadata.get(\"source\", \"unknown\") for doc in context]\n",
        "            })\n",
        "            \n",
        "            return response.content\n",
        "            \n",
        "        except Exception as e:\n",
        "            error_msg = f\"Σφάλμα: {str(e)}\"\n",
        "            self.memory.chat_memory.add_user_message(user_input)\n",
        "            self.memory.chat_memory.add_ai_message(error_msg)\n",
        "            return error_msg\n",
        "    \n",
        "    def get_conversation_history(self) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Get the full conversation history\"\"\"\n",
        "        return self.conversation_history\n",
        "    \n",
        "    def clear_memory(self):\n",
        "        \"\"\"Clear conversation memory\"\"\"\n",
        "        self.memory.clear()\n",
        "        self.conversation_history = []\n",
        "        print(\"Η μνήμη της συνομιλίας διαγράφηκε.\")\n",
        "    \n",
        "    def get_memory_summary(self) -> str:\n",
        "        \"\"\"Get a summary of the conversation\"\"\"\n",
        "        if not self.conversation_history:\n",
        "            return \"Δεν υπάρχει ιστορικό συνομιλίας.\"\n",
        "        \n",
        "        summary = f\"Συνομιλία με {len(self.conversation_history)} ερωτήσεις:\\n\"\n",
        "        for i, conv in enumerate(self.conversation_history, 1):\n",
        "            summary += f\"{i}. Ερώτηση: {conv['user'][:50]}...\\n\"\n",
        "            summary += f\"   Απάντηση: {conv['bot'][:50]}...\\n\"\n",
        "        \n",
        "        return summary\n",
        "\n",
        "# Initialize the chatbot\n",
        "chatbot = GreekDerbyChatbot(greek_derby_graph, llm)\n",
        "print(\"🤖 Greek Derby Chatbot initialized with memory!\")\n",
        "print(\"You can now have a conversation about Olympiakos vs Panathinaikos derby.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "🚀 CHATBOT READY! Choose your interaction mode:\n",
            "==================================================\n",
            "1. For interactive chat, run: interactive_chat()\n",
            "2. For quick questions, run: quick_chat('Your question in Greek')\n",
            "3. Example: quick_chat('Ποια είναι η ιστορία του ντέρμπι;')\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# Interactive Chat Function\n",
        "def interactive_chat():\n",
        "    \"\"\"Interactive chat function for the Greek Derby Chatbot\"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"🤖 GREEK DERBY CHATBOT - Interactive Mode\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"Type your questions in Greek about Olympiakos vs Panathinaikos derby\")\n",
        "    print(\"Commands:\")\n",
        "    print(\"  - Type 'quit' or 'exit' to end the conversation\")\n",
        "    print(\"  - Type 'history' to see conversation history\")\n",
        "    print(\"  - Type 'clear' to clear memory\")\n",
        "    print(\"  - Type 'help' for more commands\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    while True:\n",
        "        try:\n",
        "            # Get user input\n",
        "            user_input = input(\"\\n👤 You: \").strip()\n",
        "            \n",
        "            # Handle special commands\n",
        "            if user_input.lower() in ['quit', 'exit', 'q']:\n",
        "                print(\"\\n👋 Goodbye! Thanks for chatting about the Greek derby!\")\n",
        "                break\n",
        "            elif user_input.lower() == 'history':\n",
        "                print(\"\\n📚 Conversation History:\")\n",
        "                print(chatbot.get_memory_summary())\n",
        "                continue\n",
        "            elif user_input.lower() == 'clear':\n",
        "                chatbot.clear_memory()\n",
        "                continue\n",
        "            elif user_input.lower() == 'help':\n",
        "                print(\"\\n🆘 Available Commands:\")\n",
        "                print(\"  - Ask any question about Olympiakos vs Panathinaikos\")\n",
        "                print(\"  - 'history' - Show conversation history\")\n",
        "                print(\"  - 'clear' - Clear conversation memory\")\n",
        "                print(\"  - 'quit' or 'exit' - End conversation\")\n",
        "                continue\n",
        "            elif not user_input:\n",
        "                print(\"Please enter a question or command.\")\n",
        "                continue\n",
        "            \n",
        "            # Get chatbot response\n",
        "            print(\"\\n🤖 Bot: \", end=\"\")\n",
        "            response = chatbot.chat(user_input)\n",
        "            print(response)\n",
        "            \n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\n\\n👋 Goodbye! Thanks for chatting about the Greek derby!\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"\\n❌ Error: {e}\")\n",
        "            print(\"Please try again or type 'quit' to exit.\")\n",
        "\n",
        "# Quick chat function for single questions\n",
        "def quick_chat(question: str):\n",
        "    \"\"\"Quick chat function for single questions\"\"\"\n",
        "    print(f\"👤 You: {question}\")\n",
        "    response = chatbot.chat(question)\n",
        "    print(f\"🤖 Bot: {response}\")\n",
        "    return response\n",
        "\n",
        "# Example usage and demo\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"🚀 CHATBOT READY! Choose your interaction mode:\")\n",
        "print(\"=\"*50)\n",
        "print(\"1. For interactive chat, run: interactive_chat()\")\n",
        "print(\"2. For quick questions, run: quick_chat('Your question in Greek')\")\n",
        "print(\"3. Example: quick_chat('Ποια είναι η ιστορία του ντέρμπι;')\")\n",
        "print(\"=\"*50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🎯 DEMO: Testing the Greek Derby Chatbot\n",
            "==================================================\n",
            "Testing with sample questions...\n",
            "\n",
            "Demo Question 1:\n",
            "👤 You: Ποια είναι η ιστορία του ντέρμπι;\n",
            "🤖 Bot: Η ιστορία του ντέρμπι Ολυμπιακός - Παναθηναϊκός είναι πλούσια και γεμάτη πάθος. Πρόκειται για έναν από τους πιο σημαντικούς και ιστορικούς αγώνες του ελληνικού ποδοσφαίρου, που έχει ξεκινήσει από τη δεκαετία του 1920. Οι δύο ομάδες είναι από τις πιο επιτυχημένες στην Ελλάδα και το ντέρμπι αποτελεί σημείο αναφοράς για τους φιλάθλους τους.\n",
            "\n",
            "Μέχρι σήμερα, οι αγώνες αυτοί έχουν χαρακτηριστεί από έντονο ανταγωνισμό, ιστορικά περιστατικά και πολλές ανατροπές. Το ντέρμπι δεν είναι μόνο αθλητική αναμέτρηση, αλλά και κοινωνικό φαινόμενο, με τους φιλάθλους να ζουν κάθε αγώνα με μεγάλη ένταση και αφοσίωση. \n",
            "\n",
            "Η κόντρα έχει αναδείξει πολλές σπουδαίες προσωπικότητες και στιγμές στον ελληνικό ποδόσφαιρο, με εξέχουσες νίκες και σημαντικούς τίτλους να κρίνεται σε αυτές τις αναμετρήσεις. Σήμερα, το ντέρμπι παραμένει μια από τις πιο αναμενόμενες πτυχές του ελληνικού ποδοσφαίρου, με την ατμόσφαιρα και την ένταση να είναι πάντα στο υψηλότερο επίπεδο.\n",
            "----------------------------------------\n",
            "Demo Question 2:\n",
            "👤 You: Ποιος έχει κερδίσει περισσότερες φορές;\n",
            "🤖 Bot: Δεν γνωρίζω ποιος έχει κερδίσει περισσότερες φορές το ντέρμπι Ολυμπιακός - Παναθηναϊκός.\n",
            "----------------------------------------\n",
            "Demo Question 3:\n",
            "👤 You: Ποιοι είναι οι κορυφαίοι παίκτες;\n",
            "🤖 Bot: Οι κορυφαίοι παίκτες στην ιστορία των δύο ομάδων, Ολυμπιακό και Παναθηναϊκό, είναι πολλοί και ποικίλοι. Από τον Ολυμπιακό, ξεχωρίζουν ο Αλέξης Αλεξανδρής, οποίος είναι ο πρώτος σκόρερ στην ιστορία του συλλόγου, και ο Πρέντραγκ Τζόρτζεβιτς. Από τον Παναθηναϊκό, σημαντικές φιγούρες αποτελούν οι σπουδαίοι παίκτες όπως ο Γιώργος Καραγκούνης και ο Δημήτρης Σαραβάκος. \n",
            "\n",
            "Η λίστα με τους κορυφαίους παίκτες περιλαμβάνει επίσης πολλούς άλλους σπουδαίους αθλητές που έχουν διακριθεί με την ερυθρόλευκη και την πράσινη φανέλα. Κάθε εποχή έχει τους δικούς της αστέρες και αξέχαστες προσωπικότητες που έχουν αφήσει τη σφραγίδα τους στο ελληνικό ποδόσφαιρο.\n",
            "----------------------------------------\n",
            "\n",
            "✅ Demo completed! The chatbot is ready for interactive use.\n",
            "\n",
            "============================================================\n",
            "🚀 READY TO CHAT! Choose your option:\n",
            "============================================================\n",
            "1. Run: interactive_chat()  # For full interactive mode\n",
            "2. Run: quick_chat('Your question')  # For single questions\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Demo: Test the chatbot with sample questions\n",
        "print(\"🎯 DEMO: Testing the Greek Derby Chatbot\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Test questions in Greek\n",
        "demo_questions = [\n",
        "    \"Ποια είναι η ιστορία του ντέρμπι;\",\n",
        "    \"Ποιος έχει κερδίσει περισσότερες φορές;\",\n",
        "    \"Ποιοι είναι οι κορυφαίοι παίκτες;\"\n",
        "]\n",
        "\n",
        "print(\"Testing with sample questions...\\n\")\n",
        "\n",
        "for i, question in enumerate(demo_questions, 1):\n",
        "    print(f\"Demo Question {i}:\")\n",
        "    response = quick_chat(question)\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "print(\"\\n✅ Demo completed! The chatbot is ready for interactive use.\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"🚀 READY TO CHAT! Choose your option:\")\n",
        "print(\"=\"*60)\n",
        "print(\"1. Run: interactive_chat()  # For full interactive mode\")\n",
        "print(\"2. Run: quick_chat('Your question')  # For single questions\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Advanced Chatbot Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔧 Advanced features available:\n",
            "- get_chatbot_stats() - View conversation statistics\n",
            "- export_conversation() - Export chat to JSON file\n",
            "- chatbot.clear_memory() - Clear conversation memory\n",
            "- chatbot.get_conversation_history() - Get full history\n"
          ]
        }
      ],
      "source": [
        "# Advanced chatbot features\n",
        "def get_chatbot_stats():\n",
        "    \"\"\"Get statistics about the chatbot conversation\"\"\"\n",
        "    history = chatbot.get_conversation_history()\n",
        "    if not history:\n",
        "        return \"No conversation yet.\"\n",
        "    \n",
        "    total_questions = len(history)\n",
        "    total_chars = sum(len(conv['user']) + len(conv['bot']) for conv in history)\n",
        "    avg_question_length = sum(len(conv['user']) for conv in history) / total_questions\n",
        "    avg_answer_length = sum(len(conv['bot']) for conv in history) / total_questions\n",
        "    \n",
        "    return f\"\"\"\n",
        "📊 Chatbot Statistics:\n",
        "- Total Questions: {total_questions}\n",
        "- Total Characters: {total_chars:,}\n",
        "- Avg Question Length: {avg_question_length:.1f} chars\n",
        "- Avg Answer Length: {avg_answer_length:.1f} chars\n",
        "\"\"\"\n",
        "\n",
        "def export_conversation(filename=\"greek_derby_chat.json\"):\n",
        "    \"\"\"Export conversation to JSON file\"\"\"\n",
        "    import json\n",
        "    history = chatbot.get_conversation_history()\n",
        "    with open(filename, 'w', encoding='utf-8') as f:\n",
        "        json.dump(history, f, ensure_ascii=False, indent=2)\n",
        "    print(f\"Conversation exported to {filename}\")\n",
        "\n",
        "print(\"🔧 Advanced features available:\")\n",
        "print(\"- get_chatbot_stats() - View conversation statistics\")\n",
        "print(\"- export_conversation() - Export chat to JSON file\")\n",
        "print(\"- chatbot.clear_memory() - Clear conversation memory\")\n",
        "print(\"- chatbot.get_conversation_history() - Get full history\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "music-chatbot",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
